{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0da272e",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1209b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Project_NguyenMinhVu_2211110063\\Source\\ai\\Multi_Agent\\Source\\Main\\Tools\\poem_tools.py:8: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\") # <-- Sử dụng model bạn đã kéo về, ví dụ \"llama3\", \"mistral\"\n",
      "c:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Ensure repository root (with 'Source/ai') is on sys.path\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / 'Source' / 'ai').exists()), None)\n",
    "if project_root and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain.tools import Tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "import operator\n",
    "import requests\n",
    "from Source.ai.Multi_Agent.Source.Main.Tools import poem_tools, sentiment_tools, travel_tools, weather_tools\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_1 import Coordinator_Agent_1, Flight_Agent_1, Hotel_Agent_1, Travel_Agent_1\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_2 import Coordinator_Agent_2, Flight_Agent_2, Hotel_Agent_2, Travel_Agent_2\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_3 import Coordinator_Agent_3, Flight_Agent_3, Hotel_Agent_3, Travel_Agent_3\n",
    "from typing import TypedDict, Annotated, List, Any, Dict, Literal\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.memory import memory_manager\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.long_term_memory import long_term_memory\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e48058",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4495d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(model=\"llama3:8b\") # <-- Sử dụng model bạn đã kéo về, ví dụ \"llama3\", \"mistral\"\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    \n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c336ccd",
   "metadata": {},
   "source": [
    "Load tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f657b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherllm_agent = create_react_agent(llm, [weather_tools.weatherllm_tool], prompt) \n",
    "weatherllm_agent_executor = AgentExecutor(agent=weatherllm_agent, tools=[weather_tools.weatherllm_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_weatherllm_agent(state: AgentState):\n",
    "    result = weatherllm_agent_executor.invoke({\"input\": f\"Hiển thị thời tiết tại: {state['input']}\"})\n",
    "    return {\"messages\": [f\"Thời tiết tại: {result['output']}\"]}\n",
    "\n",
    "sentiment_agent = create_react_agent(llm, [sentiment_tools.sentiment_tool], prompt) \n",
    "sentiment_agent_executor = AgentExecutor(agent=sentiment_agent, tools=[sentiment_tools.sentiment_tool], verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "def call_sentiment_agent(state: AgentState):\n",
    "    result = sentiment_agent_executor.invoke({\"input\": f\"Phân tích cảm xúc của đoạn text sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"Phân tích cảm xúc: {result['output']}\"]} \n",
    "\n",
    "poet_agent = create_react_agent(llm, [poem_tools.poem_tool], prompt) \n",
    "poet_agent_executor = AgentExecutor(agent=poet_agent, tools=[poem_tools.poem_tool], verbose=True, handle_parsing_errors=True) \n",
    "def call_poet_agent(state: AgentState):\n",
    "    result = poet_agent_executor.invoke({\"input\": f\"Hãy viết một bài thơ về: {state['input']}\"})\n",
    "    return {\"messages\": [f\"Bài thơ: {result['output']}\"]}\n",
    "\n",
    "# weatherapi_agent = create_react_agent(llm, [weather_tools.weatherapi_tool], prompt) \n",
    "# weatherapi_agent_executor = AgentExecutor(agent=weatherapi_agent, tools=[weather_tools.weatherapi_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "# def call_weatherapi_agent(state: AgentState):\n",
    "#     result = weatherapi_agent_executor.invoke({\"input\": f\"Hiển thị thời tiết tại: {state['input']}\"})\n",
    "#     return {\"messages\": [f\"Thời tiết tại: {result['output']}\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c290bf5",
   "metadata": {},
   "source": [
    "Set langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f05e4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mLet's get started.\n",
      "\n",
      "Question: Phân tích cảm xúc của đoạn text sau: Hãy cho biết thời tiết thành phố Hồ Chí Minh hiện tại.\n",
      "Thought: Hmm, this text is asking me to analyze the sentiment of a Vietnamese sentence. I'll need to use my cultural intelligence and language processing skills to understand the context and tone of the text.\n",
      "\n",
      "Action: SentimentAnalyzer\n",
      "Action Input: Hãy cho biết thời tiết thành phố Hồ Chí Minh hiện tại.\u001b[0m"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m input_test1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMột ngày đẹp trời với bầu trời trong xanh và mặt trời tỏa nắng ấm áp.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m input_test2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHãy cho biết thời tiết thành phố Hồ Chí Minh hiện tại.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m final_state \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_test2\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKết quả cuối cùng:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m final_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langgraph\\pregel\\main.py:3026\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[0m\n\u001b[0;32m   3023\u001b[0m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m|\u001b[39m Any] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   3024\u001b[0m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 3026\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m   3027\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   3028\u001b[0m     config,\n\u001b[0;32m   3029\u001b[0m     context\u001b[38;5;241m=\u001b[39mcontext,\n\u001b[0;32m   3030\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3032\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[0;32m   3033\u001b[0m     print_mode\u001b[38;5;241m=\u001b[39mprint_mode,\n\u001b[0;32m   3034\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[0;32m   3035\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[0;32m   3036\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[0;32m   3037\u001b[0m     durability\u001b[38;5;241m=\u001b[39mdurability,\n\u001b[0;32m   3038\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3039\u001b[0m ):\n\u001b[0;32m   3040\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   3041\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langgraph\\pregel\\main.py:2647\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[0m\n\u001b[0;32m   2645\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2646\u001b[0m     loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2647\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2648\u001b[0m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2649\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2650\u001b[0m     get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2651\u001b[0m     schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2652\u001b[0m ):\n\u001b[0;32m   2653\u001b[0m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2654\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m _output(\n\u001b[0;32m   2655\u001b[0m         stream_mode, print_mode, subgraphs, stream\u001b[38;5;241m.\u001b[39mget, queue\u001b[38;5;241m.\u001b[39mEmpty\n\u001b[0;32m   2656\u001b[0m     )\n\u001b[0;32m   2657\u001b[0m loop\u001b[38;5;241m.\u001b[39mafter_tick()\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langgraph\\pregel\\_runner.py:162\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    160\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     40\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     44\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:657\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    655\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 657\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    658\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    659\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langgraph\\_internal\\_runnable.py:401\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    399\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    403\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m, in \u001b[0;36mcall_sentiment_agent\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_sentiment_agent\u001b[39m(state: AgentState):\n\u001b[1;32m---> 12\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msentiment_agent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPhân tích cảm xúc của đoạn text sau: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhân tích cảm xúc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]}\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain\\chains\\base.py:165\u001b[0m, in \u001b[0;36mChain.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[0;32m    164\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 165\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[0;32m    168\u001b[0m     )\n\u001b[0;32m    170\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[0;32m    171\u001b[0m         inputs,\n\u001b[0;32m    172\u001b[0m         outputs,\n\u001b[0;32m    173\u001b[0m         return_only_outputs,\n\u001b[0;32m    174\u001b[0m     )\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain\\agents\\agent.py:1625\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m-> 1625\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1631\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1632\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m   1633\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[0;32m   1634\u001b[0m             next_step_output,\n\u001b[0;32m   1635\u001b[0m             intermediate_steps,\n\u001b[0;32m   1636\u001b[0m             run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m   1637\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain\\agents\\agent.py:1325\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1318\u001b[0m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1322\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[0;32m   1324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[1;32m-> 1325\u001b[0m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   1334\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain\\agents\\agent.py:1408\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m   1406\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m agent_action\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_action \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[1;32m-> 1408\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_perform_agent_action\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1411\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent_action\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain\\agents\\agent.py:1433\u001b[0m, in \u001b[0;36mAgentExecutor._perform_agent_action\u001b[1;34m(self, name_to_tool_map, color_mapping, agent_action, run_manager)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         tool_run_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllm_prefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1432\u001b[0m     \u001b[38;5;66;03m# We then call the tool on the tool input to get an observation\u001b[39;00m\n\u001b[1;32m-> 1433\u001b[0m     observation \u001b[38;5;241m=\u001b[39m tool\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1434\u001b[0m         agent_action\u001b[38;5;241m.\u001b[39mtool_input,\n\u001b[0;32m   1435\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   1436\u001b[0m         color\u001b[38;5;241m=\u001b[39mcolor,\n\u001b[0;32m   1437\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1438\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_run_kwargs,\n\u001b[0;32m   1439\u001b[0m     )\n\u001b[0;32m   1440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1441\u001b[0m     tool_run_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_action_agent\u001b[38;5;241m.\u001b[39mtool_run_logging_kwargs()\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_core\\tools\\base.py:888\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[0;32m    887\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_tool_error(error_to_raise)\n\u001b[1;32m--> 888\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[0;32m    889\u001b[0m output \u001b[38;5;241m=\u001b[39m _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, status)\n\u001b[0;32m    890\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_tool_end(output, color\u001b[38;5;241m=\u001b[39mcolor, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_core\\tools\\base.py:857\u001b[0m, in \u001b[0;36mBaseTool.run\u001b[1;34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[0m\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run):\n\u001b[0;32m    856\u001b[0m         tool_kwargs \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m {config_param: config}\n\u001b[1;32m--> 857\u001b[0m     response \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run, \u001b[38;5;241m*\u001b[39mtool_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtool_kwargs)\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent_and_artifact\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_core\\tools\\simple.py:105\u001b[0m, in \u001b[0;36mTool._run\u001b[1;34m(self, config, run_manager, *args, **kwargs)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m config_param \u001b[38;5;241m:=\u001b[39m _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[0;32m    104\u001b[0m         kwargs[config_param] \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m--> 105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    106\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool does not support sync invocation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "File \u001b[1;32me:\\Project_NguyenMinhVu_2211110063\\Source\\ai\\Multi_Agent\\Source\\Main\\Tools\\sentiment_tools.py:21\u001b[0m, in \u001b[0;36manalyze_sentiment\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Phân tích cảm xúc của đoạn văn bản. Trả về Positive, Negative hoặc Neutral.\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Ở đây để đơn giản, chúng ta dùng LLM để phân tích. Trong thực tế có thể dùng model chuyên dụng.\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPhân tích cảm xúc của đoạn văn sau, chỉ trả về 1 từ \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPositive\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m, \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNegative\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m hoặc \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNeutral\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtext\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m analysis\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:393\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    389\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    390\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 393\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    394\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    395\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    396\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    397\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    398\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    399\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    400\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    401\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    402\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    403\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1019\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m   1012\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m   1017\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m   1018\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m-> 1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:837\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    835\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    836\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 837\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    838\u001b[0m                 m,\n\u001b[0;32m    839\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    840\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    841\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    842\u001b[0m             )\n\u001b[0;32m    843\u001b[0m         )\n\u001b[0;32m    844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    845\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1085\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1083\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1085\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1086\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1087\u001b[0m     )\n\u001b[0;32m   1088\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1089\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py:291\u001b[0m, in \u001b[0;36mChatOllama._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    269\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    274\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;124;03m            ])\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_chat_stream_with_aggregation(\n\u001b[0;32m    292\u001b[0m         messages,\n\u001b[0;32m    293\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    294\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m    295\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    296\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m     chat_generation \u001b[38;5;241m=\u001b[39m ChatGeneration(\n\u001b[0;32m    299\u001b[0m         message\u001b[38;5;241m=\u001b[39mAIMessage(content\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mtext),\n\u001b[0;32m    300\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39mfinal_chunk\u001b[38;5;241m.\u001b[39mgeneration_info,\n\u001b[0;32m    301\u001b[0m     )\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations\u001b[38;5;241m=\u001b[39m[chat_generation])\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py:222\u001b[0m, in \u001b[0;36mChatOllama._chat_stream_with_aggregation\u001b[1;34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_chat_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    215\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    220\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatGenerationChunk:\n\u001b[0;32m    221\u001b[0m     final_chunk: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_stream(messages, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m stream_resp:\n\u001b[0;32m    224\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m _chat_stream_response_to_chat_generation_chunk(stream_resp)\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py:194\u001b[0m, in \u001b[0;36mChatOllama._create_chat_stream\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_create_chat_stream\u001b[39m(\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    186\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m    187\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    188\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    189\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    190\u001b[0m     payload \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_messages_to_ollama_messages(messages),\n\u001b[0;32m    193\u001b[0m     }\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_stream(\n\u001b[0;32m    195\u001b[0m         payload\u001b[38;5;241m=\u001b[39mpayload, stop\u001b[38;5;241m=\u001b[39mstop, api_url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/api/chat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    196\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\requests\\models.py:869\u001b[0m, in \u001b[0;36mResponse.iter_lines\u001b[1;34m(self, chunk_size, decode_unicode, delimiter)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[0;32m    861\u001b[0m \u001b[38;5;124;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[0;32m    862\u001b[0m \u001b[38;5;124;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[0;32m    863\u001b[0m \n\u001b[0;32m    864\u001b[0m \u001b[38;5;124;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    867\u001b[0m pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 869\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_content(\n\u001b[0;32m    870\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size, decode_unicode\u001b[38;5;241m=\u001b[39mdecode_unicode\n\u001b[0;32m    871\u001b[0m ):\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pending \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    873\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m pending \u001b[38;5;241m+\u001b[39m chunk\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\requests\\utils.py:562\u001b[0m, in \u001b[0;36mstream_decode_response_unicode\u001b[1;34m(iterator, r)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    561\u001b[0m decoder \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mgetincrementaldecoder(r\u001b[38;5;241m.\u001b[39mencoding)(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplace\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m    563\u001b[0m     rv \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(chunk)\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rv:\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\urllib3\\response.py:1063\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1047\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;124;03m    'content-encoding' header.\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_chunked_reads():\n\u001b[1;32m-> 1063\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_chunked(amt, decode_content\u001b[38;5;241m=\u001b[39mdecode_content)\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\urllib3\\response.py:1219\u001b[0m, in \u001b[0;36mHTTPResponse.read_chunked\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1216\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1219\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1221\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\urllib3\\response.py:1138\u001b[0m, in \u001b[0;36mHTTPResponse._update_chunk_length\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1138\u001b[0m line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m line \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1140\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\socket.py:716\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 716\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"sentiment_analyzer\", call_sentiment_agent)\n",
    "graph_builder.add_node(\"poet\", call_poet_agent)\n",
    "graph_builder.add_node(\"weather_llm\", call_weatherllm_agent)\n",
    "#graph_builder.add_node(\"weather_api\", call_weatherapi_agent)\n",
    "\n",
    "graph_builder.set_entry_point(\"sentiment_analyzer\")\n",
    "\n",
    "graph_builder.add_edge(\"sentiment_analyzer\", \"poet\")\n",
    "graph_builder.add_edge(\"poet\", \"weather_llm\")\n",
    "#graph_builder.add_edge(\"weather_llm\", \"weather_api\")\n",
    "#graph_builder.add_edge(\"weather_api\", END)\n",
    "graph_builder.add_edge(\"weather_llm\", END)\n",
    "\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "input_test1 = \"Một ngày đẹp trời với bầu trời trong xanh và mặt trời tỏa nắng ấm áp.\"\n",
    "input_test2 = \"Hãy cho biết thời tiết thành phố Hồ Chí Minh hiện tại.\"\n",
    "\n",
    "final_state = graph.invoke({\"input\": input_test2})\n",
    "print(\"Kết quả cuối cùng:\")\n",
    "for message in final_state[\"messages\"]:\n",
    "    print(\"- \", message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360aecd9",
   "metadata": {},
   "source": [
    "MA without memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341bb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 HỆ THỐNG MULTI-AGENT DU LỊCH THÔNG MINH\n",
      "============================================================\n",
      "Bạn có thể nhập bất kỳ yêu cầu nào về du lịch!\n",
      "• Gõ 'thoát' để kết thúc\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"coordinator\", Coordinator_Agent_1.coordinator_agent)\n",
    "workflow.add_node(\"travel_agent\", Travel_Agent_1.travel_agent)\n",
    "workflow.add_node(\"hotel_agent\", Hotel_Agent_1.hotel_agent)\n",
    "workflow.add_node(\"flight_agent\", Flight_Agent_1.flight_agent)\n",
    "\n",
    "workflow.set_entry_point(\"coordinator\")\n",
    "\n",
    "def decide_next_agent(state: AgentState):\n",
    "    if state.get(\"needs_user_input\", False):\n",
    "        return \"END\"\n",
    "    return state.get(\"current_agent\", \"coordinator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator\",\n",
    "    decide_next_agent,\n",
    "    {\n",
    "        \"travel_agent\": \"travel_agent\",\n",
    "        \"hotel_agent\": \"hotel_agent\", \n",
    "        \"flight_agent\": \"flight_agent\",\n",
    "        \"coordinator\": \"coordinator\",\n",
    "        \"END\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"travel_agent\", \"coordinator\")\n",
    "workflow.add_edge(\"hotel_agent\", \"coordinator\")\n",
    "workflow.add_edge(\"flight_agent\", \"coordinator\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "def interactive_chat_system():\n",
    "    print(\"🤖 HỆ THỐNG MULTI-AGENT DU LỊCH THÔNG MINH\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Bạn có thể nhập bất kỳ yêu cầu nào về du lịch!\")\n",
    "    print(\"• Gõ 'thoát' để kết thúc\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Khởi tạo state với messages rỗng\n",
    "    state = {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\"\n",
    "    }\n",
    "    \n",
    "    # Chạy lần đầu để có lời chào\n",
    "    try:\n",
    "        output = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "        print(f\"🤖: {output['messages'][-1].content}\")\n",
    "        state = output\n",
    "    except Exception as e:\n",
    "        print(f\"🤖: Xin chào! Tôi có thể giúp gì cho chuyến đi của bạn?\")\n",
    "        state[\"messages\"] = [AIMessage(content=\"Xin chào! Tôi có thể giúp gì cho chuyến đi của bạn?\")]\n",
    "        state[\"needs_user_input\"] = True\n",
    "    \n",
    "    # Vòng lặp chat chính\n",
    "    while True:\n",
    "        try:\n",
    "            # Nhập input từ user\n",
    "            user_input = input(\"\\n👤 Bạn: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['exit', 'quit', 'thoát', 'kết thúc']:\n",
    "                print(\"🤖: Cảm ơn bạn! Hẹn gặp lại! 👋\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                print(\"🤖: Bạn muốn hỏi gì về du lịch ạ?\")\n",
    "                continue\n",
    "            \n",
    "            # Thêm user input vào conversation\n",
    "            new_messages = state['messages'] + [HumanMessage(content=user_input)]\n",
    "            state['messages'] = new_messages\n",
    "            state['needs_user_input'] = False\n",
    "            \n",
    "            # Xử lý với multi-agent system\n",
    "            output = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            \n",
    "            print(f\"👤: {user_input}\")\n",
    "            \n",
    "            # Hiển thị response\n",
    "            if output['messages']:\n",
    "                last_message = output['messages'][-1]\n",
    "                print(f\"🤖: {last_message.content}\")\n",
    "            else:\n",
    "                print(\"🤖: Tôi có thể giúp gì thêm cho bạn?\")\n",
    "            \n",
    "            # Cập nhật state\n",
    "            state = output\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n🤖: Hẹn gặp lại bạn! 👋\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"🤖: Có lỗi xảy ra: {e}\")\n",
    "            print(\"🤖: Hãy thử lại với yêu cầu khác nhé!\")\n",
    "            # Reset state\n",
    "            state = {\n",
    "                \"messages\": [AIMessage(content=\"Xin lỗi, có lỗi xảy ra. Bạn muốn hỏi gì về du lịch?\")],\n",
    "                \"current_agent\": \"coordinator\",\n",
    "                \"needs_user_input\": True,\n",
    "                \"conversation_stage\": \"greeting\"\n",
    "            }\n",
    "\n",
    "# Chạy hệ thống\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_chat_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257eafbf",
   "metadata": {},
   "source": [
    "MA with short term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bccd9aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Multi-Agent with Short-Term Memory (Agents, no Tools)\n",
      "============================================================\n",
      "Type 'exit' to quit, 'clear' to reset memory.\n",
      "\n",
      "🤖travel_agent: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "   [Memory: 12 msgs, 0 prefs]\n",
      "👤: xin chào\n",
      "\n",
      "🤖coordinator: Xin chào! Tôi rất hân hạnh được đón tiếp và trợ giúp trong chuyến hành trình của bạn!\n",
      "\n",
      "Để tạo ra một chuyến du lịch tuyệt vời, tôi cần biết hơn về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi những điều sau:\n",
      "\n",
      "* Bạn có bao nhiêu ngày cho chuyến đi?\n",
      "* Bạn quan tâm đến việc trải nghiệm văn hóa, khám phá thiên nhiên, thư giãn, hoặc là tìm kiếm các hoạt động thú vị?\n",
      "* Bạn có một danh sách yêu thích về điểm đến, ẩm thực, hay các hoạt động?\n",
      "\n",
      "Vui vẻ chia sẻ với tôi!\n",
      "   [Memory: 14 msgs, 0 prefs]\n",
      "👤: Tôi muốn lên kế hoạch du lịch\n",
      "\n",
      "🤖hotel_agent: Tuyệt vời! Tôi sẽ giúp bạn tạo ra một chuyến du lịch tuyệt vời!\n",
      "\n",
      "Để bắt đầu, có thể bạn muốn cho biết mục đích và sở thích của chuyến đi, chẳng hạn như:\n",
      "\n",
      "* Bạn đang tìm kiếm một chuyến du lịch nghỉ ngơi, thư giãn, hoặc là một chuyến hành trình khám phá?\n",
      "* Bạn có một danh sách yêu thích về điểm đến, ẩm thực, hay các hoạt động?\n",
      "\n",
      "Hãy chia sẻ với tôi những suy nghĩ và mong muốn của bạn!\n",
      "   [Memory: 17 msgs, 0 prefs]\n",
      "👋 Bye. Memory will persist for this session.\n"
     ]
    }
   ],
   "source": [
    "def create_initial_state():\n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\",\n",
    "    }\n",
    "\n",
    "AGENT_MAP = {\n",
    "    \"coordinator\": Coordinator_Agent_2.coordinator_agent,\n",
    "    \"travel_agent\": Travel_Agent_2.travel_agent,\n",
    "    \"hotel_agent\": Hotel_Agent_2.hotel_agent,\n",
    "    \"flight_agent\": Flight_Agent_2.flight_agent,\n",
    "}\n",
    "\n",
    "def run_multi_agent_chat():\n",
    "    print(\"🤖 Multi-Agent with Short-Term Memory (Agents, no Tools)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Type 'exit' to quit, 'clear' to reset memory.\")\n",
    "\n",
    "    state = create_initial_state()\n",
    "\n",
    "    while True:\n",
    "        if not state[\"needs_user_input\"]:\n",
    "            step_fn = AGENT_MAP.get(state[\"current_agent\"], Coordinator_Agent_2.coordinator_agent)\n",
    "            state = step_fn(state)\n",
    "\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\n🤖{state['current_agent']}: {last.content}\")\n",
    "\n",
    "            mem = memory_manager.get_memory()\n",
    "            print(f\"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]\")\n",
    "            continue\n",
    "\n",
    "        user_input = input(\"\\n👤 Bạn: \").strip()\n",
    "        memory_manager.get_memory().add_message(\"user\", user_input)\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"thoát\"]:\n",
    "            print(\"👋 Bye. Memory will persist for this session.\")\n",
    "            break\n",
    "\n",
    "        if user_input.lower() in [\"clear\", \"xóa\", \"reset\"]:\n",
    "            memory_manager.get_memory().clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"🧹 Đã xóa memory. Bắt đầu lại.\")\n",
    "            continue\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        print(f\"👤: {user_input}\")\n",
    "        state[\"needs_user_input\"] = False\n",
    "\n",
    "# To start the chat, run:\n",
    "run_multi_agent_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73554e0",
   "metadata": {},
   "source": [
    "Read short term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "453083c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session: session_20250925_130323\n",
      "Recent conversation:\n",
      "user: Tôi muốn lên kế hoạch du lịch\n",
      "assistant: Tuyệt vời! Tôi sẽ giúp bạn tạo ra một chuyến du lịch tuyệt vời!\n",
      "\n",
      "Để bắt đầu, có thể bạn muốn cho biết mục đích và sở thích của chuyến đi, chẳng hạn như:\n",
      "\n",
      "* Bạn đang tìm kiếm một chuyến du lịch nghỉ ngơi, thư giãn, hoặc là một chuyến hành trình khám phá?\n",
      "* Bạn có một danh sách yêu thích về điểm đến, ẩm thực, hay các hoạt động?\n",
      "\n",
      "Hãy chia sẻ với tôi những suy nghĩ và mong muốn của bạn!\n",
      "user: thoát\n",
      "\n",
      "ShortTermMemory(user_id='default_user', conversation_history=[{'role': 'assistant', 'content': 'Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?', 'timestamp': '2025-09-25T13:03:23.852161'}, {'role': 'user', 'content': 'Xin chào', 'timestamp': '2025-09-25T13:03:33.142476'}, {'role': 'assistant', 'content': 'Rất hân hạnh được giúp đỡ bạn! Để tạo ra một chuyến du lịch hoàn hảo, tôi sẽ cần biết thêm về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi những điều sau:\\n\\n* Bạn đang tìm kiếm điểm đến nào (ví dụ: beach, city, nature)?\\n* Bạn có hứng thú gì (ví dụ: ăn uống, tham gia hoạt động, mua sắm)?\\n* Bạn có một ngân sách cụ thể cho chuyến du lịch này?\\n\\nCùng tôi thảo luận và tôi sẽ tạo ra một chuyến du lịch sáng tạo, hấp dẫn cho bạn!', 'timestamp': '2025-09-25T13:04:05.498896'}, {'role': 'user', 'content': 'Tôi muốn lên kế hoạch du lịch', 'timestamp': '2025-09-25T13:04:23.252908'}, {'role': 'user', 'content': 'Tôi muốn lên kế hoạch du lịch', 'timestamp': '2025-09-25T13:04:23.672537'}, {'role': 'assistant', 'content': \"Rất hân hạnh được giúp đỡ bạn! Để tạo ra một chuyến du lịch hoàn hảo, tôi sẽ cần biết thêm về sở thích và nhu cầu của bạn. Có thể chia sẻ với tôi những điều sau:\\n\\n* Bạn đang tìm kiếm điểm đến nào (ví dụ: beach, city, nature)?\\n* Bạn có hứng thú gì (ví dụ: ăn uống, tham gia hoạt động, mua sắm)?\\n* Bạn có một ngân sách cụ thể cho chuyến du lịch này?\\n\\nCùng tôi thảo luận và tôi sẽ tạo ra một chuyến du lịch sáng tạo, hấp dẫn cho bạn!\\n\\nPlease feel free to share your preferences and I'll start creating a personalized travel plan for you!\", 'timestamp': '2025-09-25T13:04:54.972878'}, {'role': 'user', 'content': 'thoát', 'timestamp': '2025-09-25T13:05:17.434213'}, {'role': 'assistant', 'content': 'Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?', 'timestamp': '2025-09-25T13:06:05.094269'}, {'role': 'user', 'content': 'Tôi muốn lên kế hoạch du lịch', 'timestamp': '2025-09-25T13:06:19.034356'}, {'role': 'assistant', 'content': 'Rất vui được giúp! Để lên kế hoạch du lịch hiệu quả, tôi cần biết một chút về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi:\\n\\n1. Bạn mong muốn đi du lịch ở đâu (nước, thành phố, khu vực)?\\n2. Bạn có thể dành bao nhiêu ngày cho chuyến đi?\\n3. Bạn có thể chia sẻ một số sở thích hay nhu cầu đặc biệt (ví dụ: thiên nhiên, văn hóa, ẩm thực, hoạt động thể thao)?\\n\\nVí dụ, nếu bạn muốn đi du lịch ở Việt Nam và có 7 ngày rỗi rãi, tôi có thể giới thiệu cho bạn một chuyến hành trình thú vị đến Ha Long Bay, Hoi An và Ho Chi Minh City.\\n\\nWhat do you say?', 'timestamp': '2025-09-25T13:06:46.340354'}, {'role': 'user', 'content': 'thoát', 'timestamp': '2025-09-25T13:06:55.763902'}, {'role': 'assistant', 'content': 'Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?', 'timestamp': '2025-09-25T13:07:41.274666'}, {'role': 'user', 'content': 'xin chào', 'timestamp': '2025-09-25T13:07:46.071688'}, {'role': 'assistant', 'content': 'Xin chào! Tôi rất hân hạnh được đón tiếp và trợ giúp trong chuyến hành trình của bạn!\\n\\nĐể tạo ra một chuyến du lịch tuyệt vời, tôi cần biết hơn về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi những điều sau:\\n\\n* Bạn có bao nhiêu ngày cho chuyến đi?\\n* Bạn quan tâm đến việc trải nghiệm văn hóa, khám phá thiên nhiên, thư giãn, hoặc là tìm kiếm các hoạt động thú vị?\\n* Bạn có một danh sách yêu thích về điểm đến, ẩm thực, hay các hoạt động?\\n\\nVui vẻ chia sẻ với tôi!', 'timestamp': '2025-09-25T13:08:07.196085'}, {'role': 'user', 'content': 'Tôi muốn lên kế hoạch du lịch', 'timestamp': '2025-09-25T13:08:33.899718'}, {'role': 'user', 'content': 'Tôi muốn lên kế hoạch du lịch', 'timestamp': '2025-09-25T13:08:34.321547'}, {'role': 'assistant', 'content': 'Tuyệt vời! Tôi sẽ giúp bạn tạo ra một chuyến du lịch tuyệt vời!\\n\\nĐể bắt đầu, có thể bạn muốn cho biết mục đích và sở thích của chuyến đi, chẳng hạn như:\\n\\n* Bạn đang tìm kiếm một chuyến du lịch nghỉ ngơi, thư giãn, hoặc là một chuyến hành trình khám phá?\\n* Bạn có một danh sách yêu thích về điểm đến, ẩm thực, hay các hoạt động?\\n\\nHãy chia sẻ với tôi những suy nghĩ và mong muốn của bạn!', 'timestamp': '2025-09-25T13:08:56.982787'}, {'role': 'user', 'content': 'thoát', 'timestamp': '2025-09-25T13:09:11.180399'}], user_preferences={}, booking_info={}, last_updated=datetime.datetime(2025, 9, 25, 13, 9, 11, 180399), session_id='session_20250925_130323')\n",
      "ShortTermMemory(user_id='user_id', conversation_history=[], user_preferences={}, booking_info={}, last_updated=datetime.datetime(2025, 9, 25, 13, 9, 48, 141703), session_id='session_20250925_130948')\n",
      "2025-09-25T13:03:23.852161 | assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T13:03:33.142476 | user: Xin chào\n",
      "2025-09-25T13:04:05.498896 | assistant: Rất hân hạnh được giúp đỡ bạn! Để tạo ra một chuyến du lịch hoàn hảo, tôi sẽ cần biết thêm về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi những điều sau:\n",
      "\n",
      "* Bạn đang tìm kiếm điểm đến nào (ví dụ: beach, city, nature)?\n",
      "* Bạn có hứng thú gì (ví dụ: ăn uống, tham gia hoạt động, mua sắm)?\n",
      "* Bạn có một ngân sách cụ thể cho chuyến du lịch này?\n",
      "\n",
      "Cùng tôi thảo luận và tôi sẽ tạo ra một chuyến du lịch sáng tạo, hấp dẫn cho bạn!\n",
      "2025-09-25T13:04:23.252908 | user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:04:23.672537 | user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:04:54.972878 | assistant: Rất hân hạnh được giúp đỡ bạn! Để tạo ra một chuyến du lịch hoàn hảo, tôi sẽ cần biết thêm về sở thích và nhu cầu của bạn. Có thể chia sẻ với tôi những điều sau:\n",
      "\n",
      "* Bạn đang tìm kiếm điểm đến nào (ví dụ: beach, city, nature)?\n",
      "* Bạn có hứng thú gì (ví dụ: ăn uống, tham gia hoạt động, mua sắm)?\n",
      "* Bạn có một ngân sách cụ thể cho chuyến du lịch này?\n",
      "\n",
      "Cùng tôi thảo luận và tôi sẽ tạo ra một chuyến du lịch sáng tạo, hấp dẫn cho bạn!\n",
      "\n",
      "Please feel free to share your preferences and I'll start creating a personalized travel plan for you!\n",
      "2025-09-25T13:05:17.434213 | user: thoát\n",
      "2025-09-25T13:06:05.094269 | assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T13:06:19.034356 | user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:06:46.340354 | assistant: Rất vui được giúp! Để lên kế hoạch du lịch hiệu quả, tôi cần biết một chút về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi:\n",
      "\n",
      "1. Bạn mong muốn đi du lịch ở đâu (nước, thành phố, khu vực)?\n",
      "2. Bạn có thể dành bao nhiêu ngày cho chuyến đi?\n",
      "3. Bạn có thể chia sẻ một số sở thích hay nhu cầu đặc biệt (ví dụ: thiên nhiên, văn hóa, ẩm thực, hoạt động thể thao)?\n",
      "\n",
      "Ví dụ, nếu bạn muốn đi du lịch ở Việt Nam và có 7 ngày rỗi rãi, tôi có thể giới thiệu cho bạn một chuyến hành trình thú vị đến Ha Long Bay, Hoi An và Ho Chi Minh City.\n",
      "\n",
      "What do you say?\n",
      "2025-09-25T13:06:55.763902 | user: thoát\n",
      "2025-09-25T13:07:41.274666 | assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T13:07:46.071688 | user: xin chào\n",
      "2025-09-25T13:08:07.196085 | assistant: Xin chào! Tôi rất hân hạnh được đón tiếp và trợ giúp trong chuyến hành trình của bạn!\n",
      "\n",
      "Để tạo ra một chuyến du lịch tuyệt vời, tôi cần biết hơn về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi những điều sau:\n",
      "\n",
      "* Bạn có bao nhiêu ngày cho chuyến đi?\n",
      "* Bạn quan tâm đến việc trải nghiệm văn hóa, khám phá thiên nhiên, thư giãn, hoặc là tìm kiếm các hoạt động thú vị?\n",
      "* Bạn có một danh sách yêu thích về điểm đến, ẩm thực, hay các hoạt động?\n",
      "\n",
      "Vui vẻ chia sẻ với tôi!\n",
      "2025-09-25T13:08:33.899718 | user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:08:34.321547 | user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:08:56.982787 | assistant: Tuyệt vời! Tôi sẽ giúp bạn tạo ra một chuyến du lịch tuyệt vời!\n",
      "\n",
      "Để bắt đầu, có thể bạn muốn cho biết mục đích và sở thích của chuyến đi, chẳng hạn như:\n",
      "\n",
      "* Bạn đang tìm kiếm một chuyến du lịch nghỉ ngơi, thư giãn, hoặc là một chuyến hành trình khám phá?\n",
      "* Bạn có một danh sách yêu thích về điểm đến, ẩm thực, hay các hoạt động?\n",
      "\n",
      "Hãy chia sẻ với tôi những suy nghĩ và mong muốn của bạn!\n",
      "2025-09-25T13:09:11.180399 | user: thoát\n"
     ]
    }
   ],
   "source": [
    "mem = memory_manager.get_memory()  # hoặc memory_manager.get_memory(\"user_id\")\n",
    "print(mem.get_context_summary())\n",
    "print(memory_manager.get_memory())\n",
    "print(memory_manager.get_memory(\"user_id\"))\n",
    "\n",
    "for m in mem.conversation_history:\n",
    "    if m[\"role\"] in [\"user\", \"assistant\"]:\n",
    "        print(f\"{m['timestamp']} | {m['role']}: {m['content']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2049829a",
   "metadata": {},
   "source": [
    "MA with long term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97357d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Multi-Agent with Short-Term & Long-Term Memory\n",
      "============================================================\n",
      "Commands: 'exit', 'clear' (short-term), 'clear_all' (both), 'mem_stats'\n",
      "\n",
      "🤖travel_agent: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "   [Memory: 23 msgs, 0 prefs]\n",
      "👤: Tôi muốn lên kế hoạch cho chuyến du lịch\n",
      "\n",
      "🤖coordinator: Thật tuyệt vời! Tôi sẽ giúp bạn tạo một chuyến du lịch sáng tạo và hấp dẫn.\n",
      "\n",
      "Before we start, may I know a bit more about your preferences?\n",
      "\n",
      "* Are you looking for an adventure trip, relaxation getaway, or cultural exploration?\n",
      "* What is your budget for this trip?\n",
      "* How many days do you have available for the trip?\n",
      "* Do you have any specific destinations in mind or are you open to suggestions?\n",
      "\n",
      "Let's get started!\n",
      "   [Memory: 25 msgs, 0 prefs]\n",
      "👤: Tôi muốn 1 chuyến du lịch nghĩ dưỡng tại Hà Nội\n",
      "\n",
      "🤖hotel_agent: Hà Nội, một thành phố cổ kính và lãng mạn. Tôi có thể giúp bạn tạo một chuyến du lịch nghỉ dưỡng tuyệt vời tại Hà Nội.\n",
      "\n",
      "Để bắt đầu, có thể tôi hỏi: Bạn có ưu tiên nào nhất định, chẳng hạn như:\n",
      "\n",
      "* Trải nghiệm ẩm thực Hà Nội\n",
      "* Khám phá các di tích lịch sử và văn hóa\n",
      "* Đi tham quan các điểm đến nổi tiếng của Hà Nội\n",
      "* Ngủ nghỉ tại một khách sạn 5 sao\n",
      "\n",
      "Hay bạn có thể cho tôi biết thêm về sở thích và nhu cầu của bạn?\n",
      "   [Memory: 28 msgs, 0 prefs]\n",
      "👋 Bye. Long-term memory has been saved.\n"
     ]
    }
   ],
   "source": [
    "def run_multi_agent_chat():\n",
    "    print(\"🤖 Multi-Agent with Short-Term & Long-Term Memory\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Commands: 'exit', 'clear' (short-term), 'clear_all' (both), 'mem_stats'\")\n",
    "\n",
    "    state = create_initial_state()\n",
    "\n",
    "    while True:\n",
    "        if not state[\"needs_user_input\"]:\n",
    "            step_fn = AGENT_MAP.get(state[\"current_agent\"], Coordinator_Agent_2.coordinator_agent)\n",
    "            state = step_fn(state)\n",
    "\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\n🤖{state['current_agent']}: {last.content}\")\n",
    "\n",
    "            mem = memory_manager.get_memory()\n",
    "            print(f\"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]\")\n",
    "            continue\n",
    "\n",
    "        user_input = input(\"\\n👤 Bạn: \").strip()\n",
    "        memory_manager.add_message(\"user\", user_input)\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"thoát\"]:\n",
    "            print(\"👋 Bye. Long-term memory has been saved.\")\n",
    "            break\n",
    "\n",
    "        if user_input.lower() in [\"clear\", \"xóa\", \"reset\"]:\n",
    "            memory_manager.clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"🧹 Đã xóa short-term memory. Long-term memory vẫn giữ.\")\n",
    "            continue\n",
    "\n",
    "        if user_input.lower() in [\"clear_all\", \"xóa_all\", \"reset_all\"]:\n",
    "            memory_manager.clear_memory(also_long_term=True)\n",
    "            long_term_memory.clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"🧹 Đã xóa cả short-term và long-term memory.\")\n",
    "            continue\n",
    "\n",
    "        if user_input.lower() in [\"mem_stats\", \"memory_stats\"]:\n",
    "            stats = long_term_memory.collection.count()\n",
    "            print(f\"📊 Long-term Memory: {stats} items stored\")\n",
    "            continue\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        print(f\"👤: {user_input}\")\n",
    "        state[\"needs_user_input\"] = False\n",
    "\n",
    "run_multi_agent_chat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93660a5",
   "metadata": {},
   "source": [
    "Read long term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db176aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total items: 68\n",
      "2025-09-25T13:03:23.852161 session_20250925_130323 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T13:03:33.142476 session_20250925_130323 user : user: Xin chào\n",
      "2025-09-25T13:04:05.498896 session_20250925_130323 assistant : assistant: Rất hân hạnh được giúp đỡ bạn! Để tạo ra một chuyến du lịch hoàn hảo, tôi sẽ cần biết thêm về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi những điều sau:\n",
      "\n",
      "* Bạn đang tìm kiếm điểm đến nào (ví dụ: beach, city, nature)?\n",
      "* Bạn có hứng thú gì (ví dụ: ăn uống, tham gia hoạt động, mua sắm)?\n",
      "* Bạn có một ngân sách cụ thể cho chuyến du lịch này?\n",
      "\n",
      "Cùng tôi thảo luận và tôi sẽ tạo ra một chuyến du lịch sáng tạo, hấp dẫn cho bạn!\n",
      "2025-09-25T13:04:23.252908 session_20250925_130323 user : user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:04:23.672537 session_20250925_130323 user : user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:04:54.972878 session_20250925_130323 assistant : assistant: Rất hân hạnh được giúp đỡ bạn! Để tạo ra một chuyến du lịch hoàn hảo, tôi sẽ cần biết thêm về sở thích và nhu cầu của bạn. Có thể chia sẻ với tôi những điều sau:\n",
      "\n",
      "* Bạn đang tìm kiếm điểm đến nào (ví dụ: beach, city, nature)?\n",
      "* Bạn có hứng thú gì (ví dụ: ăn uống, tham gia hoạt động, mua sắm)?\n",
      "* Bạn có một ngân sách cụ thể cho chuyến du lịch này?\n",
      "\n",
      "Cùng tôi thảo luận và tôi sẽ tạo ra một chuyến du lịch sáng tạo, hấp dẫn cho bạn!\n",
      "\n",
      "Please feel free to share your preferences and I'll start creating a personalized travel plan for you!\n",
      "2025-09-25T13:05:17.434213 session_20250925_130323 user : user: thoát\n",
      "2025-09-25T13:06:05.094269 session_20250925_130323 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T13:06:19.034356 session_20250925_130323 user : user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:06:46.340354 session_20250925_130323 assistant : assistant: Rất vui được giúp! Để lên kế hoạch du lịch hiệu quả, tôi cần biết một chút về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi:\n",
      "\n",
      "1. Bạn mong muốn đi du lịch ở đâu (nước, thành phố, khu vực)?\n",
      "2. Bạn có thể dành bao nhiêu ngày cho chuyến đi?\n",
      "3. Bạn có thể chia sẻ một số sở thích hay nhu cầu đặc biệt (ví dụ: thiên nhiên, văn hóa, ẩm thực, hoạt động thể thao)?\n",
      "\n",
      "Ví dụ, nếu bạn muốn đi du lịch ở Việt Nam và có 7 ngày rỗi rãi, tôi có thể giới thiệu cho bạn một chuyến hành trình thú vị đến Ha Long Bay, Hoi An và Ho Chi Minh City.\n",
      "\n",
      "What do you say?\n",
      "2025-09-25T13:06:55.763902 session_20250925_130323 user : user: thoát\n",
      "2025-09-25T13:07:41.274666 session_20250925_130323 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T13:07:46.071688 session_20250925_130323 user : user: xin chào\n",
      "2025-09-25T13:08:07.196085 session_20250925_130323 assistant : assistant: Xin chào! Tôi rất hân hạnh được đón tiếp và trợ giúp trong chuyến hành trình của bạn!\n",
      "\n",
      "Để tạo ra một chuyến du lịch tuyệt vời, tôi cần biết hơn về sở thích và nhu cầu của bạn. Bạn có thể chia sẻ với tôi những điều sau:\n",
      "\n",
      "* Bạn có bao nhiêu ngày cho chuyến đi?\n",
      "* Bạn quan tâm đến việc trải nghiệm văn hóa, khám phá thiên nhiên, thư giãn, hoặc là tìm kiếm các hoạt động thú vị?\n",
      "* Bạn có một danh sách yêu thích về điểm đến, ẩm thực, hay các hoạt động?\n",
      "\n",
      "Vui vẻ chia sẻ với tôi!\n",
      "2025-09-25T13:08:33.899718 session_20250925_130323 user : user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:08:34.321547 session_20250925_130323 user : user: Tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T13:08:56.982787 session_20250925_130323 assistant : assistant: Tuyệt vời! Tôi sẽ giúp bạn tạo ra một chuyến du lịch tuyệt vời!\n",
      "\n",
      "Để bắt đầu, có thể bạn muốn cho biết mục đích và sở thích của chuyến đi, chẳng hạn như:\n",
      "\n",
      "* Bạn đang tìm kiếm một chuyến du lịch nghỉ ngơi, thư giãn, hoặc là một chuyến hành trình khám phá?\n",
      "* Bạn có một danh sách yêu thích về điểm đến, ẩm thực, hay các hoạt động?\n",
      "\n",
      "Hãy chia sẻ với tôi những suy nghĩ và mong muốn của bạn!\n",
      "2025-09-25T13:09:11.180399 session_20250925_130323 user : user: thoát\n",
      "2025-09-25T13:12:33.319524 session_20250925_130323 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T13:13:05.194674 session_20250925_130323 user : user: Tôi muốn lên kế hoạch cho chuyến du lịch\n",
      "2025-09-25T13:13:34.227700 session_20250925_130323 assistant : assistant: Rất hân hạnh được giúp đỡ!\n",
      "\n",
      "Để tạo ra một chuyến du lịch sáng tạo và hấp dẫn, tôi cần biết những điều sau:\n",
      "\n",
      "* Bạn thích làm gì trong chuyến du lịch (ví dụ: khám phá văn hóa, hoạt động ngoài trời, thư giãn trên bãi biển)?\n",
      "* Bạn có ai accompany cùng (các thành viên trong gia đình, bạn bè hay người yêu)?\n",
      "* Bạn có một ngân sách cụ thể cho chuyến du lịch không?\n",
      "* Bạn có thời gian cụ thể để đi du lịch không?\n",
      "\n",
      "Vì vậy, tôi sẽ cần biết thêm về sở thích và nhu cầu của bạn. Xin hãy chia sẻ với tôi!\n",
      "\n",
      "(And by the way, I have a few destination ideas in mind to get us started)\n",
      "\n",
      "What's your travel style?\n",
      "2025-09-25T13:14:24.366326 session_20250925_130323 user : user: thoát\n",
      "2025-09-25T13:15:30.043944 session_20250925_130323 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T13:15:45.824534 session_20250925_130323 user : user: Tôi muốn lên kế hoạch cho chuyến du lịch\n",
      "2025-09-25T13:16:02.551677 session_20250925_130323 assistant : assistant: Thật tuyệt vời! Tôi sẽ giúp bạn tạo một chuyến du lịch sáng tạo và hấp dẫn.\n",
      "\n",
      "Before we start, may I know a bit more about your preferences?\n",
      "\n",
      "* Are you looking for an adventure trip, relaxation getaway, or cultural exploration?\n",
      "* What is your budget for this trip?\n",
      "* How many days do you have available for the trip?\n",
      "* Do you have any specific destinations in mind or are you open to suggestions?\n",
      "\n",
      "Let's get started!\n",
      "2025-09-25T13:16:41.054263 session_20250925_130323 user : user: Tôi muốn 1 chuyến du lịch nghĩ dưỡng tại Hà Nội\n",
      "2025-09-25T13:16:41.740746 session_20250925_130323 user : user: Tôi muốn 1 chuyến du lịch nghĩ dưỡng tại Hà Nội\n",
      "2025-09-25T13:17:07.374250 session_20250925_130323 assistant : assistant: Hà Nội, một thành phố cổ kính và lãng mạn. Tôi có thể giúp bạn tạo một chuyến du lịch nghỉ dưỡng tuyệt vời tại Hà Nội.\n",
      "\n",
      "Để bắt đầu, có thể tôi hỏi: Bạn có ưu tiên nào nhất định, chẳng hạn như:\n",
      "\n",
      "* Trải nghiệm ẩm thực Hà Nội\n",
      "* Khám phá các di tích lịch sử và văn hóa\n",
      "* Đi tham quan các điểm đến nổi tiếng của Hà Nội\n",
      "* Ngủ nghỉ tại một khách sạn 5 sao\n",
      "\n",
      "Hay bạn có thể cho tôi biết thêm về sở thích và nhu cầu của bạn?\n",
      "2025-09-25T13:17:23.348042 session_20250925_130323 user : user: thoát\n",
      "2025-09-25T13:27:35.307766 session_20250925_130323 user : user: bạn có gợi ý cho tôi địa điểm khác không ?\n",
      "2025-09-25T13:27:35.969652 session_20250925_130323 user : user: bạn có gợi ý cho tôi địa điểm khác không ?\n",
      "2025-09-25T13:28:24.123997 session_20250925_130323 assistant : assistant: I think you're looking for some alternative destination ideas, aren't you?\n",
      "\n",
      "Well, I'd be happy to suggest a few places that might interest you!\n",
      "\n",
      "* Hoi An: A charming coastal town known for its ancient architecture, delicious seafood, and vibrant night market.\n",
      "* Ha Long Bay: A stunning natural wonder with towering limestone karsts and emerald waters. Perfect for a relaxing getaway or an adventure-filled trip!\n",
      "* Sapa: A picturesque mountain town surrounded by lush green hills and valleys, perfect for trekking, hiking, or simply taking in the breathtaking views.\n",
      "\n",
      "Which one of these destinations sparks your interest?\n",
      "\n",
      "Let me know, and I can give you some insider tips on how to make the most of your trip!\n",
      "2025-09-25T13:29:19.544198 session_20250925_130323 user : user: thoát\n",
      "2025-09-25T13:31:11.974607 session_20250925_130323 user : user: Bạn có điểm du lịch nào không ?\n",
      "2025-09-25T13:31:12.640494 session_20250925_130323 user : user: Bạn có điểm du lịch nào không ?\n",
      "2025-09-25T13:31:59.119815 session_20250925_130323 assistant : assistant: I think you're asking about destination ideas again!\n",
      "\n",
      "Well, let me tell you that I have a few favorite destinations that are perfect for a relaxing getaway or an adventure-filled trip!\n",
      "\n",
      "* Phu Quoc Island: A tropical paradise with crystal-clear waters, powdery white sand beaches, and a relaxed atmosphere.\n",
      "* Da Nang: A coastal city with a vibrant night market, stunning beaches, and a mix of cultural attractions and outdoor activities.\n",
      "* Ninh Binh: A historic town with ancient temples, scenic rivers, and a rich cultural heritage.\n",
      "\n",
      "Which one of these destinations sounds appealing to you?\n",
      "\n",
      "Let me know, and I can give you some insider tips on how to make the most of your trip!\n",
      "2025-09-25T13:32:36.115917 session_20250925_130323 user : user: thoát\n",
      "2025-09-25T14:08:12.329331 session_20250925_130323 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T14:08:38.674565 session_20250925_130323 user : user: Tôi muốn lên lịch cho chuyến đi du lịch Hà Nội\n",
      "2025-09-25T14:08:39.443403 session_20250925_130323 user : user: Tôi muốn lên lịch cho chuyến đi du lịch Hà Nội\n",
      "2025-09-25T14:09:20.560616 session_20250925_130323 assistant : assistant: Hà Nội - một thành phố hấp dẫn với nhiều di tích lịch sử và văn hóa. Để lên kế hoạch cho chuyến đi của bạn, có lẽ chúng ta nên thảo luận về chi tiết hơn.\n",
      "\n",
      "Có thể các bạn muốn tôi giúp gì? Bạn có nhu cầu về điểm đến, thời gian lưu trú hay những trải nghiệm mới trong chuyến đi này?\n",
      "\n",
      "(Viết lại theo dạng câu hỏi để xác nhận)\n",
      "2025-09-25T14:09:38.828620 session_20250925_130323 user : user: thoát\n",
      "2025-09-25T14:49:50.649993 session_20250925_144950 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T14:49:57.749731 session_20250925_144950 user : user: xin chào\n",
      "2025-09-25T14:49:58.101245 session_20250925_144950 user : user: xin chào\n",
      "2025-09-25T14:50:19.538209 session_20250925_144950 assistant : assistant: Xin chào! Bạn cần giúp đỡ về gì hôm nay? Chuyến đi, khách sạn, máy bay... ?\n",
      "2025-09-25T14:51:11.042162 session_20250925_144950 user : user: thoát\n",
      "2025-09-25T14:51:20.162181 session_20250925_144950 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T14:51:36.159835 session_20250925_144950 user : user: tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T14:51:36.596503 session_20250925_144950 user : user: tôi muốn lên kế hoạch du lịch\n",
      "2025-09-25T14:52:04.869909 session_20250925_144950 assistant : assistant: Rất hân hạnh được giúp đỡ! Bạn có nhu cầu lên kế hoạch du lịch cho chuyến đi sắp tới, phải không? \n",
      "\n",
      "Để tôi có thể trợ giúp tốt hơn, có thể bạn chia sẻ một chút về chuyến đi của mình, chẳng hạn như:\n",
      "\n",
      "* Điểm đến mong muốn\n",
      "* Thời gian dự kiến di chuyển\n",
      "* Loại hình du lịch (lịch sự, giải trí, kinh doanh, v.v.)\n",
      "\n",
      "Chất lượng thời gian và thông tin này sẽ giúp tôi cung cấp cho bạn những gợi ý và tư vấn phù hợp nhất!\n",
      "2025-09-25T14:52:57.446332 session_20250925_144950 user : user: thoát\n",
      "2025-09-25T14:56:07.064418 session_20250925_144950 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T14:56:28.926007 session_20250925_144950 user : user: tôi muốn lên kế hoạch cho chuyến du lịch Hà Nội\n",
      "2025-09-25T14:56:29.627744 session_20250925_144950 user : user: tôi muốn lên kế hoạch cho chuyến du lịch Hà Nội\n",
      "2025-09-25T14:56:44.092705 session_20250925_144950 assistant : assistant: Hà Nội là một thành phố tuyệt vời! Bạn có nhu cầu cụ thể về chuyến du lịch, ví dụ như điểm đến, thời gian, số người đi haybudget? Hoặc tôi có thể gợi ý những địa danh và hoạt động thú vị tại Hà Nội?\n",
      "2025-09-25T14:56:54.087354 session_20250925_144950 user : user: thoát\n",
      "2025-09-25T14:57:29.408519 session_20250925_144950 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T14:57:33.528585 session_20250925_144950 user : user: thoát\n",
      "2025-09-25T14:57:53.492276 session_20250925_144950 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T14:57:56.684631 session_20250925_144950 user : user: thoát\n",
      "2025-09-25T14:58:27.518056 session_20250925_144950 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T14:58:30.961319 session_20250925_144950 user : user: thoát\n",
      "2025-09-25T15:03:03.201267 session_20250925_150303 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T15:03:07.403363 session_20250925_150303 user : user: thoát\n",
      "2025-09-25T15:10:17.893726 session_20250925_151001 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T15:10:21.472032 session_20250925_151001 user : user: thoát\n",
      "2025-09-25T15:15:57.619270 session_20250925_151001 user : user: thoát\n"
     ]
    }
   ],
   "source": [
    "def read_long_term_memory():\n",
    "    print(\"Total items:\", long_term_memory.collection.count())\n",
    "    col = long_term_memory.collection\n",
    "    all_items = col.get(include=[\"documents\",\"metadatas\"])\n",
    "    for doc, meta in zip(all_items[\"documents\"], all_items[\"metadatas\"]):\n",
    "        print(meta.get(\"timestamp\"), meta.get(\"session_id\"), meta.get(\"role\"), \":\", doc)\n",
    "        \n",
    "read_long_term_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f946ae8",
   "metadata": {},
   "source": [
    "Set new session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16415e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New session started: session_20250925_151417\n"
     ]
    }
   ],
   "source": [
    "def new_session(user_id: str = \"default_user\", clear_history: bool = True, keep_preferences: bool = True, auto_continue: bool = False, replay_last_n: int = 20) -> str:\n",
    "    sid = memory_manager.start_new_session(user_id=user_id, clear_history=clear_history, keep_preferences=keep_preferences)\n",
    "    print(f\"New session started: {sid}\")\n",
    "    if auto_continue:\n",
    "        initial_state = build_state_from_memory(user_id=user_id, max_messages=replay_last_n)\n",
    "        run_langgraph_chat(initial_state=initial_state)\n",
    "    return sid\n",
    "\n",
    "sid = new_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a009ba",
   "metadata": {},
   "source": [
    "Print session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "710d4a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['session_20250925_130323', 'session_20250925_144950', 'session_20250925_150303', 'session_20250925_151001']\n"
     ]
    }
   ],
   "source": [
    "all_items = long_term_memory.collection.get(include=[\"metadatas\"])\n",
    "session_ids = sorted({m.get(\"session_id\") for m in all_items[\"metadatas\"] if m})\n",
    "print(session_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11a58660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous chat history:\n",
      "2025-09-25T15:10:17.893726 session_20250925_151001 assistant : assistant: Xin chào! Tôi là trợ lý du lịch đa nhiệm. Tôi có thể giúp gì cho chuyến đi của bạn?\n",
      "2025-09-25T15:10:21.472032 session_20250925_151001 user : user: thoát\n",
      "2025-09-25T15:15:57.619270 session_20250925_151001 user : user: thoát\n",
      "2025-09-25T15:19:04.791208 session_20250925_151001 user : user: thoát\n",
      "2025-09-25T15:20:39.525862 session_20250925_151001 user : user: Tôi muốn lên kế hoạch du lịch hà Nội\n",
      "2025-09-25T15:20:39.938372 session_20250925_151001 user : user: Tôi muốn lên kế hoạch du lịch hà Nội\n",
      "2025-09-25T15:21:11.216768 session_20250925_151001 assistant : assistant: Hà Nội - một trong những thành phố cổ kính và giàu có về di tích lịch sử của Việt Nam.\n",
      "\n",
      "Để giúp tôi phục vụ bạn tốt hơn, có thể chia sẻ với tôi về ý định du lịch của bạn. Bạn muốn đi đâu? Bạn có nhu cầu gì (ví dụ: nghỉ dưỡng, thăm quan di tích, trải nghiệm văn hóa)? \n",
      "\n",
      "Tôi sẽ giúp bạn lên kế hoạch du lịch hà Nội phù hợp nhất!\n",
      "2025-09-25T15:21:19.533060 session_20250925_151001 user : user: thoát\n",
      "Resumed 8 messages from long-term: session_20250925_151001\n",
      "🤖 Multi-Agent (LangGraph) with Long-Term Memory\n",
      "============================================================\n",
      "Commands: 'exit', 'clear' (STM), 'clear_all' (STM+LTM), 'mem_stats'\n",
      "👤: Tôi muốn nghỉ dưỡng trong tầm 3 ngày\n",
      "\n",
      "🤖hotel_agent: Xin chào! Tôi thấy rằng bạn muốn nghỉ dưỡng trong tầm 3 ngày tại Hà Nội.\n",
      "\n",
      "Tôi có thể hỏi thêm một chút để giúp tôi phục vụ bạn tốt hơn. Bạn có nhu cầu gì về nơi ở (khách sạn, homestay, resort)? Hay bạn đã có một nơi cụ thể trong mind?\n",
      "\n",
      "Và cũng có thể hỏi về những hoạt động bạn muốn làm trong 3 ngày của mình tại Hà Nội? Ví dụ: thăm quan di tích, đi bộ đường phố, thử các món ăn đường phố...?\n",
      "\n",
      "Tôi sẽ giúp bạn lên kế hoạch du lịch hà Nội phù hợp nhất!\n",
      "   [Memory: 26 msgs, 0 prefs]\n",
      "👋 Bye. Long-term memory has been saved.\n"
     ]
    }
   ],
   "source": [
    "def read_long_term_memory_by_session_id(session_id: str):\n",
    "    col = long_term_memory.collection\n",
    "    all_items = col.get(include=[\"documents\",\"metadatas\"])\n",
    "    for doc, meta in zip(all_items[\"documents\"], all_items[\"metadatas\"]):\n",
    "        if meta.get(\"session_id\") == session_id:\n",
    "            print(meta.get(\"timestamp\"), meta.get(\"session_id\"), meta.get(\"role\"), \":\", doc)\n",
    "\n",
    "# Khai báo State cho LangGraph\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n",
    "    current_agent: str\n",
    "    needs_user_input: bool\n",
    "    conversation_stage: Literal[\"greeting\", \"planning\", \"booking\", \"confirmation\", \"completed\"]\n",
    "\n",
    "def create_initial_state() -> AgentState:\n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\",\n",
    "    }\n",
    "\n",
    "# Hàm điều hướng sau node coordinator\n",
    "def decide_next_agent(state: AgentState):\n",
    "    if state.get(\"needs_user_input\", False):\n",
    "        return \"END\"\n",
    "    return state.get(\"current_agent\", \"coordinator\")\n",
    "\n",
    "# Build đồ thị LangGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"coordinator\", Coordinator_Agent_3.coordinator_agent)\n",
    "workflow.add_node(\"travel_agent\", Travel_Agent_3.travel_agent)\n",
    "workflow.add_node(\"hotel_agent\", Hotel_Agent_3.hotel_agent)\n",
    "workflow.add_node(\"flight_agent\", Flight_Agent_3.flight_agent)\n",
    "\n",
    "workflow.set_entry_point(\"coordinator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator\",\n",
    "    decide_next_agent,\n",
    "    {\n",
    "        \"travel_agent\": \"travel_agent\",\n",
    "        \"hotel_agent\": \"hotel_agent\",\n",
    "        \"flight_agent\": \"flight_agent\",\n",
    "        \"coordinator\": \"coordinator\",\n",
    "        \"END\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Sau khi agent chuyên trách chạy xong, quay lại coordinator\n",
    "workflow.add_edge(\"travel_agent\", \"coordinator\")\n",
    "workflow.add_edge(\"hotel_agent\", \"coordinator\")\n",
    "workflow.add_edge(\"flight_agent\", \"coordinator\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "def run_langgraph_chat(initial_state=None):\n",
    "    print(\"🤖 Multi-Agent (LangGraph) with Long-Term Memory\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Commands: 'exit', 'clear' (STM), 'clear_all' (STM+LTM), 'mem_stats'\")\n",
    "\n",
    "    state = initial_state or create_initial_state()\n",
    "\n",
    "    # KHÔNG auto-invoke nếu đã có messages (tránh chào lại)\n",
    "    if not state.get(\"messages\"):\n",
    "        try:\n",
    "            state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\n🤖{state['current_agent']}: {last.content}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    while True:\n",
    "        if not state.get(\"needs_user_input\", True):\n",
    "            state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\n🤖{state['current_agent']}: {last.content}\")\n",
    "            mem = memory_manager.get_memory()\n",
    "            print(f\"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]\")\n",
    "            continue\n",
    "\n",
    "        user_input = input(\"\\n👤 Bạn: \").strip()\n",
    "        memory_manager.add_message(\"user\", user_input)\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"thoát\"]:\n",
    "            print(\"👋 Bye. Long-term memory has been saved.\")\n",
    "            break\n",
    "        if user_input.lower() in [\"clear\", \"xóa\", \"reset\"]:\n",
    "            memory_manager.clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"🧹 Đã xóa short-term memory. Long-term vẫn giữ.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"clear_all\", \"xóa_all\", \"reset_all\"]:\n",
    "            memory_manager.clear_memory(also_long_term=True)\n",
    "            state = create_initial_state()\n",
    "            print(\"🧹 Đã xóa cả short-term và long-term memory.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"mem_stats\", \"memory_stats\"]:\n",
    "            print(f\"📊 Long-term Memory: {long_term_memory.collection.count()} items\")\n",
    "            continue\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        print(f\"👤: {user_input}\")\n",
    "        state[\"needs_user_input\"] = False\n",
    "def build_state_from_memory(user_id: str = \"default_user\", max_messages: int = 10):\n",
    "    mem = memory_manager.get_memory(user_id)\n",
    "    msgs = []\n",
    "    ctrl = {\"thoát\",\"exit\",\"quit\",\"xóa\",\"clear\",\"reset\",\"clear_all\",\"xóa_all\",\"reset_all\"}\n",
    "    for m in mem.conversation_history[-max_messages:]:\n",
    "        content = (m.get(\"content\") or \"\").strip()\n",
    "        if content.lower() in ctrl:\n",
    "            continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role == \"user\":\n",
    "            msgs.append(HumanMessage(content=content))\n",
    "        else:\n",
    "            msgs.append(AIMessage(content=content))\n",
    "    needs_user_input = True if msgs and isinstance(msgs[-1], AIMessage) else False\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": needs_user_input,\n",
    "        \"conversation_stage\": \"planning\",\n",
    "    }\n",
    "def continue_chat_from_session(session_id: str, user_id: str = \"default_user\", replay_last_n: int = 20):\n",
    "    print(\"Previous chat history:\")\n",
    "    read_long_term_memory_by_session_id(\"session_20250925_151001\")\n",
    "    loaded = memory_manager.resume_session(session_id, user_id=user_id, replay_last_n=replay_last_n)\n",
    "    print(f\"Resumed {loaded} messages from long-term: {session_id}\")\n",
    "    initial_state = build_state_from_memory(user_id=user_id, max_messages=replay_last_n)\n",
    "    run_langgraph_chat(initial_state=initial_state)\n",
    "\n",
    "# run_langgraph_chat()\n",
    "# hoặc tiếp nối từ 1 session cụ thể:\n",
    "continue_chat_from_session(\"session_20250925_151001\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
