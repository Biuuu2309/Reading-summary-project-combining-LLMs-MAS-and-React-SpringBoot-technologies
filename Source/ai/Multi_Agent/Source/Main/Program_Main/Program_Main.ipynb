{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0da272e",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1209b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Project_NguyenMinhVu_2211110063\\Source\\ai\\Multi_Agent\\Source\\Main\\Tools\\poem_tools.py:8: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\") # <-- Sá»­ dá»¥ng model báº¡n Ä‘Ã£ kÃ©o vá», vÃ­ dá»¥ \"llama3\", \"mistral\"\n",
      "c:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Ensure repository root (with 'Source/ai') is on sys.path\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / 'Source' / 'ai').exists()), None)\n",
    "if project_root and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain.tools import Tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "import operator\n",
    "import requests\n",
    "from Source.ai.Multi_Agent.Source.Main.Tools import poem_tools, sentiment_tools, travel_tools, weather_tools\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_1 import Coordinator_Agent_1, Flight_Agent_1, Hotel_Agent_1, Travel_Agent_1\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_2 import Coordinator_Agent_2, Flight_Agent_2, Hotel_Agent_2, Travel_Agent_2\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_3 import Coordinator_Agent_3, Flight_Agent_3, Hotel_Agent_3, Travel_Agent_3\n",
    "from typing import TypedDict, Annotated, List, Any, Dict, Literal\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.memory import memory_manager\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.long_term_memory import long_term_memory\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e48058",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4495d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(model=\"llama3:8b\")\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    \n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c336ccd",
   "metadata": {},
   "source": [
    "Load tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherllm_agent = create_react_agent(llm, [weather_tools.weatherllm_tool], prompt) \n",
    "weatherllm_agent_executor = AgentExecutor(agent=weatherllm_agent, tools=[weather_tools.weatherllm_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_weatherllm_agent(state: AgentState):\n",
    "    result = weatherllm_agent_executor.invoke({\"input\": f\"Hiá»ƒn thá»‹ thá»i tiáº¿t táº¡i: {state['input']}\"})\n",
    "    return {\"messages\": [f\"Thá»i tiáº¿t táº¡i: {result['output']}\"]}\n",
    "\n",
    "sentiment_agent = create_react_agent(llm, [sentiment_tools.sentiment_tool], prompt) \n",
    "sentiment_agent_executor = AgentExecutor(agent=sentiment_agent, tools=[sentiment_tools.sentiment_tool], verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "def call_sentiment_agent(state: AgentState):\n",
    "    result = sentiment_agent_executor.invoke({\"input\": f\"PhÃ¢n tÃ­ch cáº£m xÃºc cá»§a Ä‘oáº¡n text sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"PhÃ¢n tÃ­ch cáº£m xÃºc: {result['output']}\"]} \n",
    "\n",
    "poet_agent = create_react_agent(llm, [poem_tools.poem_tool], prompt) \n",
    "poet_agent_executor = AgentExecutor(agent=poet_agent, tools=[poem_tools.poem_tool], verbose=True, handle_parsing_errors=True) \n",
    "def call_poet_agent(state: AgentState):\n",
    "    result = poet_agent_executor.invoke({\"input\": f\"HÃ£y viáº¿t má»™t bÃ i thÆ¡ vá»: {state['input']}\"})\n",
    "    return {\"messages\": [f\"BÃ i thÆ¡: {result['output']}\"]}\n",
    "\n",
    "# weatherapi_agent = create_react_agent(llm, [weather_tools.weatherapi_tool], prompt) \n",
    "# weatherapi_agent_executor = AgentExecutor(agent=weatherapi_agent, tools=[weather_tools.weatherapi_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "# def call_weatherapi_agent(state: AgentState):\n",
    "#     result = weatherapi_agent_executor.invoke({\"input\": f\"Hiá»ƒn thá»‹ thá»i tiáº¿t táº¡i: {state['input']}\"})\n",
    "#     return {\"messages\": [f\"Thá»i tiáº¿t táº¡i: {result['output']}\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c290bf5",
   "metadata": {},
   "source": [
    "Set langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"sentiment_analyzer\", call_sentiment_agent)\n",
    "graph_builder.add_node(\"poet\", call_poet_agent)\n",
    "graph_builder.add_node(\"weather_llm\", call_weatherllm_agent)\n",
    "#graph_builder.add_node(\"weather_api\", call_weatherapi_agent)\n",
    "\n",
    "graph_builder.set_entry_point(\"sentiment_analyzer\")\n",
    "\n",
    "graph_builder.add_edge(\"sentiment_analyzer\", \"poet\")\n",
    "graph_builder.add_edge(\"poet\", \"weather_llm\")\n",
    "#graph_builder.add_edge(\"weather_llm\", \"weather_api\")\n",
    "#graph_builder.add_edge(\"weather_api\", END)\n",
    "graph_builder.add_edge(\"weather_llm\", END)\n",
    "\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "input_test1 = \"Má»™t ngÃ y Ä‘áº¹p trá»i vá»›i báº§u trá»i trong xanh vÃ  máº·t trá»i tá»a náº¯ng áº¥m Ã¡p.\"\n",
    "input_test2 = \"HÃ£y cho biáº¿t thá»i tiáº¿t thÃ nh phá»‘ Há»“ ChÃ­ Minh hiá»‡n táº¡i.\"\n",
    "\n",
    "final_state = graph.invoke({\"input\": input_test2})\n",
    "print(\"Káº¿t quáº£ cuá»‘i cÃ¹ng:\")\n",
    "for message in final_state[\"messages\"]:\n",
    "    print(\"- \", message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360aecd9",
   "metadata": {},
   "source": [
    "MA without memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"coordinator\", Coordinator_Agent_1.coordinator_agent)\n",
    "workflow.add_node(\"travel_agent\", Travel_Agent_1.travel_agent)\n",
    "workflow.add_node(\"hotel_agent\", Hotel_Agent_1.hotel_agent)\n",
    "workflow.add_node(\"flight_agent\", Flight_Agent_1.flight_agent)\n",
    "\n",
    "workflow.set_entry_point(\"coordinator\")\n",
    "\n",
    "def decide_next_agent(state: AgentState):\n",
    "    if state.get(\"needs_user_input\", False):\n",
    "        return \"END\"\n",
    "    return state.get(\"current_agent\", \"coordinator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator\",\n",
    "    decide_next_agent,\n",
    "    {\n",
    "        \"travel_agent\": \"travel_agent\",\n",
    "        \"hotel_agent\": \"hotel_agent\", \n",
    "        \"flight_agent\": \"flight_agent\",\n",
    "        \"coordinator\": \"coordinator\",\n",
    "        \"END\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"travel_agent\", \"coordinator\")\n",
    "workflow.add_edge(\"hotel_agent\", \"coordinator\")\n",
    "workflow.add_edge(\"flight_agent\", \"coordinator\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# Há»† THá»NG CHAT Tá»° Äá»˜NG - ÄÃƒ Sá»¬A Lá»–I\n",
    "def interactive_chat_system():\n",
    "    print(\"ðŸ¤– Há»† THá»NG MULTI-AGENT DU Lá»ŠCH THÃ”NG MINH\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Báº¡n cÃ³ thá»ƒ nháº­p báº¥t ká»³ yÃªu cáº§u nÃ o vá» du lá»‹ch!\")\n",
    "    print(\"â€¢ GÃµ 'thoÃ¡t' Ä‘á»ƒ káº¿t thÃºc\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Khá»Ÿi táº¡o state vá»›i messages rá»—ng\n",
    "    state = {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\"\n",
    "    }\n",
    "    \n",
    "    # Cháº¡y láº§n Ä‘áº§u Ä‘á»ƒ cÃ³ lá»i chÃ o\n",
    "    try:\n",
    "        output = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "        print(f\"ðŸ¤–: {output['messages'][-1].content}\")\n",
    "        state = output\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ¤–: Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho chuyáº¿n Ä‘i cá»§a báº¡n?\")\n",
    "        state[\"messages\"] = [AIMessage(content=\"Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho chuyáº¿n Ä‘i cá»§a báº¡n?\")]\n",
    "        state[\"needs_user_input\"] = True\n",
    "    \n",
    "    # VÃ²ng láº·p chat chÃ­nh\n",
    "    while True:\n",
    "        try:\n",
    "            # Nháº­p input tá»« user\n",
    "            user_input = input(\"\\nðŸ‘¤ Báº¡n: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['exit', 'quit', 'thoÃ¡t', 'káº¿t thÃºc']:\n",
    "                print(\"ðŸ¤–: Cáº£m Æ¡n báº¡n! Háº¹n gáº·p láº¡i! ðŸ‘‹\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                print(\"ðŸ¤–: Báº¡n muá»‘n há»i gÃ¬ vá» du lá»‹ch áº¡?\")\n",
    "                continue\n",
    "            \n",
    "            # ThÃªm user input vÃ o conversation\n",
    "            new_messages = state['messages'] + [HumanMessage(content=user_input)]\n",
    "            state['messages'] = new_messages\n",
    "            state['needs_user_input'] = False\n",
    "            \n",
    "            # Xá»­ lÃ½ vá»›i multi-agent system\n",
    "            output = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            \n",
    "            print(f\"ðŸ‘¤: {user_input}\")\n",
    "            \n",
    "            # Hiá»ƒn thá»‹ response\n",
    "            if output['messages']:\n",
    "                last_message = output['messages'][-1]\n",
    "                print(f\"ðŸ¤–: {last_message.content}\")\n",
    "            else:\n",
    "                print(\"ðŸ¤–: TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ thÃªm cho báº¡n?\")\n",
    "            \n",
    "            # Cáº­p nháº­t state\n",
    "            state = output\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nðŸ¤–: Háº¹n gáº·p láº¡i báº¡n! ðŸ‘‹\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"ðŸ¤–: CÃ³ lá»—i xáº£y ra: {e}\")\n",
    "            print(\"ðŸ¤–: HÃ£y thá»­ láº¡i vá»›i yÃªu cáº§u khÃ¡c nhÃ©!\")\n",
    "            # Reset state\n",
    "            state = {\n",
    "                \"messages\": [AIMessage(content=\"Xin lá»—i, cÃ³ lá»—i xáº£y ra. Báº¡n muá»‘n há»i gÃ¬ vá» du lá»‹ch?\")],\n",
    "                \"current_agent\": \"coordinator\",\n",
    "                \"needs_user_input\": True,\n",
    "                \"conversation_stage\": \"greeting\"\n",
    "            }\n",
    "\n",
    "# Cháº¡y há»‡ thá»‘ng\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_chat_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257eafbf",
   "metadata": {},
   "source": [
    "MA with short term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd9aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_state():\n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\",\n",
    "    }\n",
    "\n",
    "AGENT_MAP = {\n",
    "    \"coordinator\": Coordinator_Agent_2.coordinator_agent,\n",
    "    \"travel_agent\": Travel_Agent_2.travel_agent,\n",
    "    \"hotel_agent\": Hotel_Agent_2.hotel_agent,\n",
    "    \"flight_agent\": Flight_Agent_2.flight_agent,\n",
    "}\n",
    "\n",
    "def run_multi_agent_chat():\n",
    "    print(\"ðŸ¤– Multi-Agent with Short-Term Memory (Agents, no Tools)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Type 'exit' to quit, 'clear' to reset memory.\")\n",
    "\n",
    "    state = create_initial_state()\n",
    "\n",
    "    while True:\n",
    "        if not state[\"needs_user_input\"]:\n",
    "            step_fn = AGENT_MAP.get(state[\"current_agent\"], Coordinator_Agent_2.coordinator_agent)\n",
    "            state = step_fn(state)\n",
    "\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\nðŸ¤–{state['current_agent']}: {last.content}\")\n",
    "\n",
    "            mem = memory_manager.get_memory()\n",
    "            print(f\"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]\")\n",
    "            continue\n",
    "\n",
    "        user_input = input(\"\\nðŸ‘¤ Báº¡n: \").strip()\n",
    "        memory_manager.get_memory().add_message(\"user\", user_input)\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"thoÃ¡t\"]:\n",
    "            print(\"ðŸ‘‹ Bye. Memory will persist for this session.\")\n",
    "            break\n",
    "\n",
    "        if user_input.lower() in [\"clear\", \"xÃ³a\", \"reset\"]:\n",
    "            memory_manager.get_memory().clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"ðŸ§¹ ÄÃ£ xÃ³a memory. Báº¯t Ä‘áº§u láº¡i.\")\n",
    "            continue\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        print(f\"ðŸ‘¤: {user_input}\")\n",
    "        state[\"needs_user_input\"] = False\n",
    "\n",
    "# To start the chat, run:\n",
    "run_multi_agent_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73554e0",
   "metadata": {},
   "source": [
    "Read short term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453083c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = memory_manager.get_memory()  # hoáº·c memory_manager.get_memory(\"user_id\")\n",
    "print(mem.get_context_summary())\n",
    "print(memory_manager.get_memory())\n",
    "print(memory_manager.get_memory(\"user_id\"))\n",
    "\n",
    "for m in mem.conversation_history:\n",
    "    if m[\"role\"] in [\"user\", \"assistant\"]:\n",
    "        print(f\"{m['timestamp']} | {m['role']}: {m['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
