{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0da272e",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1209b1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Project_NguyenMinhVu_2211110063\\Source\\ai\\Multi_Agent\\Source\\Main\\Tools\\poem_tools.py:8: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\") # <-- Sử dụng model bạn đã kéo về, ví dụ \"llama3\", \"mistral\"\n",
      "c:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Ensure repository root (with 'Source/ai') is on sys.path\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / 'Source' / 'ai').exists()), None)\n",
    "if project_root and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain.tools import Tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "import operator\n",
    "import requests\n",
    "from Source.ai.Multi_Agent.Source.Main.Tools import poem_tools, sentiment_tools, travel_tools, weather_tools\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_1 import Coordinator_Agent_1, Flight_Agent_1, Hotel_Agent_1, Travel_Agent_1\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_2 import Coordinator_Agent_2, Flight_Agent_2, Hotel_Agent_2, Travel_Agent_2\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_3 import Coordinator_Agent_3, Flight_Agent_3, Hotel_Agent_3, Travel_Agent_3\n",
    "from typing import TypedDict, Annotated, List, Any, Dict, Literal\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.memory import memory_manager\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.long_term_memory import long_term_memory\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import uuid\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e48058",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4495d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(model=\"llama3:8b\")\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    \n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c336ccd",
   "metadata": {},
   "source": [
    "Load tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "weatherllm_agent = create_react_agent(llm, [weather_tools.weatherllm_tool], prompt) \n",
    "weatherllm_agent_executor = AgentExecutor(agent=weatherllm_agent, tools=[weather_tools.weatherllm_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_weatherllm_agent(state: AgentState):\n",
    "    result = weatherllm_agent_executor.invoke({\"input\": f\"Hiển thị thời tiết tại: {state['input']}\"})\n",
    "    return {\"messages\": [f\"Thời tiết tại: {result['output']}\"]}\n",
    "\n",
    "sentiment_agent = create_react_agent(llm, [sentiment_tools.sentiment_tool], prompt) \n",
    "sentiment_agent_executor = AgentExecutor(agent=sentiment_agent, tools=[sentiment_tools.sentiment_tool], verbose=True, handle_parsing_errors=True)\n",
    "\n",
    "def call_sentiment_agent(state: AgentState):\n",
    "    result = sentiment_agent_executor.invoke({\"input\": f\"Phân tích cảm xúc của đoạn text sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"Phân tích cảm xúc: {result['output']}\"]} \n",
    "\n",
    "poet_agent = create_react_agent(llm, [poem_tools.poem_tool], prompt) \n",
    "poet_agent_executor = AgentExecutor(agent=poet_agent, tools=[poem_tools.poem_tool], verbose=True, handle_parsing_errors=True) \n",
    "def call_poet_agent(state: AgentState):\n",
    "    result = poet_agent_executor.invoke({\"input\": f\"Hãy viết một bài thơ về: {state['input']}\"})\n",
    "    return {\"messages\": [f\"Bài thơ: {result['output']}\"]}\n",
    "\n",
    "# weatherapi_agent = create_react_agent(llm, [weather_tools.weatherapi_tool], prompt) \n",
    "# weatherapi_agent_executor = AgentExecutor(agent=weatherapi_agent, tools=[weather_tools.weatherapi_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "# def call_weatherapi_agent(state: AgentState):\n",
    "#     result = weatherapi_agent_executor.invoke({\"input\": f\"Hiển thị thời tiết tại: {state['input']}\"})\n",
    "#     return {\"messages\": [f\"Thời tiết tại: {result['output']}\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c290bf5",
   "metadata": {},
   "source": [
    "Set langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f05e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"sentiment_analyzer\", call_sentiment_agent)\n",
    "graph_builder.add_node(\"poet\", call_poet_agent)\n",
    "graph_builder.add_node(\"weather_llm\", call_weatherllm_agent)\n",
    "#graph_builder.add_node(\"weather_api\", call_weatherapi_agent)\n",
    "\n",
    "graph_builder.set_entry_point(\"sentiment_analyzer\")\n",
    "\n",
    "graph_builder.add_edge(\"sentiment_analyzer\", \"poet\")\n",
    "graph_builder.add_edge(\"poet\", \"weather_llm\")\n",
    "#graph_builder.add_edge(\"weather_llm\", \"weather_api\")\n",
    "#graph_builder.add_edge(\"weather_api\", END)\n",
    "graph_builder.add_edge(\"weather_llm\", END)\n",
    "\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "input_test1 = \"Một ngày đẹp trời với bầu trời trong xanh và mặt trời tỏa nắng ấm áp.\"\n",
    "input_test2 = \"Hãy cho biết thời tiết thành phố Hồ Chí Minh hiện tại.\"\n",
    "\n",
    "final_state = graph.invoke({\"input\": input_test2})\n",
    "print(\"Kết quả cuối cùng:\")\n",
    "for message in final_state[\"messages\"]:\n",
    "    print(\"- \", message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360aecd9",
   "metadata": {},
   "source": [
    "MA without memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9341bb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"coordinator\", Coordinator_Agent_1.coordinator_agent)\n",
    "workflow.add_node(\"travel_agent\", Travel_Agent_1.travel_agent)\n",
    "workflow.add_node(\"hotel_agent\", Hotel_Agent_1.hotel_agent)\n",
    "workflow.add_node(\"flight_agent\", Flight_Agent_1.flight_agent)\n",
    "\n",
    "workflow.set_entry_point(\"coordinator\")\n",
    "\n",
    "def decide_next_agent(state: AgentState):\n",
    "    if state.get(\"needs_user_input\", False):\n",
    "        return \"END\"\n",
    "    return state.get(\"current_agent\", \"coordinator\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator\",\n",
    "    decide_next_agent,\n",
    "    {\n",
    "        \"travel_agent\": \"travel_agent\",\n",
    "        \"hotel_agent\": \"hotel_agent\", \n",
    "        \"flight_agent\": \"flight_agent\",\n",
    "        \"coordinator\": \"coordinator\",\n",
    "        \"END\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"travel_agent\", \"coordinator\")\n",
    "workflow.add_edge(\"hotel_agent\", \"coordinator\")\n",
    "workflow.add_edge(\"flight_agent\", \"coordinator\")\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "# HỆ THỐNG CHAT TỰ ĐỘNG - ĐÃ SỬA LỖI\n",
    "def interactive_chat_system():\n",
    "    print(\"🤖 HỆ THỐNG MULTI-AGENT DU LỊCH THÔNG MINH\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Bạn có thể nhập bất kỳ yêu cầu nào về du lịch!\")\n",
    "    print(\"• Gõ 'thoát' để kết thúc\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Khởi tạo state với messages rỗng\n",
    "    state = {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\"\n",
    "    }\n",
    "    \n",
    "    # Chạy lần đầu để có lời chào\n",
    "    try:\n",
    "        output = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "        print(f\"🤖: {output['messages'][-1].content}\")\n",
    "        state = output\n",
    "    except Exception as e:\n",
    "        print(f\"🤖: Xin chào! Tôi có thể giúp gì cho chuyến đi của bạn?\")\n",
    "        state[\"messages\"] = [AIMessage(content=\"Xin chào! Tôi có thể giúp gì cho chuyến đi của bạn?\")]\n",
    "        state[\"needs_user_input\"] = True\n",
    "    \n",
    "    # Vòng lặp chat chính\n",
    "    while True:\n",
    "        try:\n",
    "            # Nhập input từ user\n",
    "            user_input = input(\"\\n👤 Bạn: \").strip()\n",
    "            \n",
    "            if user_input.lower() in ['exit', 'quit', 'thoát', 'kết thúc']:\n",
    "                print(\"🤖: Cảm ơn bạn! Hẹn gặp lại! 👋\")\n",
    "                break\n",
    "            \n",
    "            if not user_input:\n",
    "                print(\"🤖: Bạn muốn hỏi gì về du lịch ạ?\")\n",
    "                continue\n",
    "            \n",
    "            # Thêm user input vào conversation\n",
    "            new_messages = state['messages'] + [HumanMessage(content=user_input)]\n",
    "            state['messages'] = new_messages\n",
    "            state['needs_user_input'] = False\n",
    "            \n",
    "            # Xử lý với multi-agent system\n",
    "            output = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            \n",
    "            print(f\"👤: {user_input}\")\n",
    "            \n",
    "            # Hiển thị response\n",
    "            if output['messages']:\n",
    "                last_message = output['messages'][-1]\n",
    "                print(f\"🤖: {last_message.content}\")\n",
    "            else:\n",
    "                print(\"🤖: Tôi có thể giúp gì thêm cho bạn?\")\n",
    "            \n",
    "            # Cập nhật state\n",
    "            state = output\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n🤖: Hẹn gặp lại bạn! 👋\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"🤖: Có lỗi xảy ra: {e}\")\n",
    "            print(\"🤖: Hãy thử lại với yêu cầu khác nhé!\")\n",
    "            # Reset state\n",
    "            state = {\n",
    "                \"messages\": [AIMessage(content=\"Xin lỗi, có lỗi xảy ra. Bạn muốn hỏi gì về du lịch?\")],\n",
    "                \"current_agent\": \"coordinator\",\n",
    "                \"needs_user_input\": True,\n",
    "                \"conversation_stage\": \"greeting\"\n",
    "            }\n",
    "\n",
    "# Chạy hệ thống\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_chat_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257eafbf",
   "metadata": {},
   "source": [
    "MA with short term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccd9aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_initial_state():\n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\",\n",
    "    }\n",
    "\n",
    "AGENT_MAP = {\n",
    "    \"coordinator\": Coordinator_Agent_2.coordinator_agent,\n",
    "    \"travel_agent\": Travel_Agent_2.travel_agent,\n",
    "    \"hotel_agent\": Hotel_Agent_2.hotel_agent,\n",
    "    \"flight_agent\": Flight_Agent_2.flight_agent,\n",
    "}\n",
    "\n",
    "def run_multi_agent_chat():\n",
    "    print(\"🤖 Multi-Agent with Short-Term Memory (Agents, no Tools)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Type 'exit' to quit, 'clear' to reset memory.\")\n",
    "\n",
    "    state = create_initial_state()\n",
    "\n",
    "    while True:\n",
    "        if not state[\"needs_user_input\"]:\n",
    "            step_fn = AGENT_MAP.get(state[\"current_agent\"], Coordinator_Agent_2.coordinator_agent)\n",
    "            state = step_fn(state)\n",
    "\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\n🤖{state['current_agent']}: {last.content}\")\n",
    "\n",
    "            mem = memory_manager.get_memory()\n",
    "            print(f\"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]\")\n",
    "            continue\n",
    "\n",
    "        user_input = input(\"\\n👤 Bạn: \").strip()\n",
    "        memory_manager.get_memory().add_message(\"user\", user_input)\n",
    "        \n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"thoát\"]:\n",
    "            print(\"👋 Bye. Memory will persist for this session.\")\n",
    "            break\n",
    "\n",
    "        if user_input.lower() in [\"clear\", \"xóa\", \"reset\"]:\n",
    "            memory_manager.get_memory().clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"🧹 Đã xóa memory. Bắt đầu lại.\")\n",
    "            continue\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        print(f\"👤: {user_input}\")\n",
    "        state[\"needs_user_input\"] = False\n",
    "\n",
    "# To start the chat, run:\n",
    "run_multi_agent_chat()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73554e0",
   "metadata": {},
   "source": [
    "Read short term memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453083c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = memory_manager.get_memory()  # hoặc memory_manager.get_memory(\"user_id\")\n",
    "print(mem.get_context_summary())\n",
    "print(memory_manager.get_memory())\n",
    "print(memory_manager.get_memory(\"user_id\"))\n",
    "\n",
    "for m in mem.conversation_history:\n",
    "    if m[\"role\"] in [\"user\", \"assistant\"]:\n",
    "        print(f\"{m['timestamp']} | {m['role']}: {m['content']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
