{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "887a225f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhv\\anaconda3\\envs\\pytorch-env\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "e:\\Project_NguyenMinhVu_2211110063\\Source\\ai\\Multi_Agent\\Source\\Main\\Tools\\poem_tools.py:14: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3:8b\") # <-- S·ª≠ d·ª•ng model b·∫°n ƒë√£ k√©o v·ªÅ, v√≠ d·ª• \"llama3\", \"mistral\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure repository root (with 'Source/ai') is on sys.path\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / 'Source' / 'ai').exists()), None)\n",
    "if project_root and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain.tools import Tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "import operator\n",
    "import requests\n",
    "from Source.ai.Multi_Agent.Source.Main.Tools import poem_tools, sentiment_tools, travel_tools, weather_tools\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_1 import Coordinator_Agent_1, Flight_Agent_1, Hotel_Agent_1, Travel_Agent_1\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_2 import Coordinator_Agent_2, Flight_Agent_2, Hotel_Agent_2, Travel_Agent_2\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_3 import Coordinator_Agent_3, Flight_Agent_3, Hotel_Agent_3, Travel_Agent_3, Aggregator_Agent_3\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_Summary import Abstracter_Agent, Aggregator_Agent, Coordinator_Agent, Evaluator_Agent, Extractor_Agent, GradeCalibrator_Agent, OCR_Agent, SpellChecker_Agent\n",
    "from typing import TypedDict, Annotated, List, Any, Dict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.memory import memory_manager\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.long_term_memory import long_term_memory\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import uuid\n",
    "import os\n",
    "#from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e42904",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(model=\"llama3:8b\") # <-- S·ª≠ d·ª•ng model b·∫°n ƒë√£ k√©o v·ªÅ, v√≠ d·ª• \"llama3\", \"mistral\"\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    \n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea45d564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New session started: session_20251028_140755\n"
     ]
    }
   ],
   "source": [
    "def new_session(user_id: str = \"default_user\", clear_history: bool = True, keep_preferences: bool = True, auto_continue: bool = False, replay_last_n: int = 20) -> str:\n",
    "    sid = memory_manager.start_new_session(user_id=user_id, clear_history=clear_history, keep_preferences=keep_preferences)\n",
    "    print(f\"New session started: {sid}\")\n",
    "    if auto_continue:\n",
    "        initial_state = build_state_from_memory(user_id=user_id, max_messages=replay_last_n)\n",
    "        run_langgraph_chat(initial_state=initial_state)\n",
    "    return sid\n",
    "\n",
    "sid = new_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03660b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'session_20250925_130323', 'session_20250925_144950', 'session_20250925_150303', 'session_20250925_151001', 'session_20250927_162902', 'session_20250927_164507', 'session_20250928_092221', 'session_20250928_154914', 'session_20250928_155638', 'session_20251001_160456', 'session_20251002_093329', 'session_20251002_110113', 'session_20251002_143156', 'session_20251028_105421', 'session_20251028_123837', 'session_20251028_132438', 'session_20251028_134421', 'session_20251028_140050']\n"
     ]
    }
   ],
   "source": [
    "all_items = long_term_memory.collection.get(include=[\"metadatas\"])\n",
    "session_ids = sorted({m.get(\"session_id\") for m in all_items[\"metadatas\"] if m})\n",
    "print(session_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "578789a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes wired: aggregator added between specialist agents and coordinator.\n"
     ]
    }
   ],
   "source": [
    "def create_initial_state() -> AgentState:\n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\",\n",
    "    }\n",
    "state = create_initial_state()\n",
    "try:\n",
    "    state = app.invoke(state, config={\"recursion_limit\": 20})\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Nodes wired: aggregator added between specialist agents and coordinator.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91e4eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_long_term_memory_by_session_id(session_id: str):\n",
    "    col = long_term_memory.collection\n",
    "    all_items = col.get(include=[\"documents\",\"metadatas\"])\n",
    "    for doc, meta in zip(all_items[\"documents\"], all_items[\"metadatas\"]):\n",
    "        if meta.get(\"session_id\") == session_id:\n",
    "            print(meta.get(\"timestamp\"), meta.get(\"session_id\"), meta.get(\"role\"), \":\", doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fd543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous chat history:\n",
      "Resumed 0 messages from long-term: session_20251028_140755\n",
      "ü§ñ Multi-Agent System Summary For Primary School Students\n",
      "============================================================\n",
      "Commands: 'exit', 'clear' (STM), 'clear_all' (STM+LTM), 'mem_stats'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class AgentStateFixed(TypedDict):\n",
    "    messages: Annotated[List[Any], operator.add]  # S·ª≠ d·ª•ng Annotated v·ªõi operator.add\n",
    "    current_agent: str\n",
    "    needs_user_input: bool\n",
    "    conversation_stage: Literal[\"greeting\", \"planning\", \"checking\", \"processing\", \"aggregator\", \"completed\"]\n",
    "    check: Literal[\"exactly\", \"not exactly\"] = Field(\n",
    "        description=\"Decide if the text is exactly the same as the original text.\",\n",
    "    )\n",
    "    feedback: str = Field(\n",
    "        description=\"If the text is not exactly the same as the original text, provide feedback on how to improve it.\",\n",
    "    )\n",
    "\n",
    "# H√†m ƒëi·ªÅu h∆∞·ªõng sau node coordinator\n",
    "def decide_next_agent(state: AgentState):\n",
    "    # Ch·ªâ k·∫øt th√∫c khi user mu·ªën tho√°t ho·∫∑c workflow ho√†n th√†nh\n",
    "    if state.get(\"needs_user_input\", False) and state.get(\"conversation_stage\") == \"completed\":\n",
    "        return \"END\"\n",
    "    return state.get(\"current_agent\", \"coordinator_agent\")\n",
    "\n",
    "def route_check(state: AgentState):\n",
    "    # Ki·ªÉm tra xem c√≥ field 'check' kh√¥ng, n·∫øu kh√¥ng c√≥ th√¨ m·∫∑c ƒë·ªãnh l√† \"exactly\"\n",
    "    check_value = state.get(\"check\", \"exactly\")\n",
    "    if check_value == \"exactly\":\n",
    "        return \"Accepted\"\n",
    "    elif check_value == \"not exactly\":\n",
    "        state[\"retry_count\"] = state.get(\"retry_count\", 0) + 1\n",
    "        if state[\"retry_count\"] > 3:\n",
    "            return \"Rejected + Feedback (max retries)\"\n",
    "        return \"Rejected + Feedback\"\n",
    "    else:\n",
    "        return \"Accepted\"  # M·∫∑c ƒë·ªãnh ch·∫•p nh·∫≠n\n",
    "    \n",
    "# Build ƒë·ªì th·ªã LangGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"coordinator_agent\", Coordinator_Agent.coordinator_agent)\n",
    "workflow.add_node(\"reader_ocr_agent\", OCR_Agent.ocr_agent)\n",
    "workflow.add_node(\"spellchecker_agent\", SpellChecker_Agent.spellchecker_agent)\n",
    "workflow.add_node(\"extractor_agent\", Extractor_Agent.extractor_agent)\n",
    "workflow.add_node(\"abstracter_agent\", Abstracter_Agent.abstracter_agent)\n",
    "workflow.add_node(\"grade_calibrator_agent\", GradeCalibrator_Agent.grade_calibrator_agent)\n",
    "workflow.add_node(\"evaluator_agent\", Evaluator_Agent.evaluator_agent)\n",
    "workflow.add_node(\"aggregator_agent\", Aggregator_Agent.aggregator_agent)\n",
    "\n",
    "workflow.set_entry_point(\"coordinator_agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator_agent\",\n",
    "    decide_next_agent,\n",
    "    {\n",
    "        \"reader_ocr_agent\": \"reader_ocr_agent\",\n",
    "        \"spellchecker_agent\": \"spellchecker_agent\",\n",
    "        \"extractor_agent\": \"extractor_agent\",\n",
    "        \"abstracter_agent\": \"abstracter_agent\",\n",
    "        \"grade_calibrator_agent\": \"grade_calibrator_agent\",\n",
    "        \"evaluator_agent\": \"evaluator_agent\",\n",
    "        \"aggregator_agent\": \"aggregator_agent\",\n",
    "        \"coordinator_agent\": \"coordinator_agent\",\n",
    "        \"END\": END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"reader_ocr_agent\", \"spellchecker_agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"spellchecker_agent\",\n",
    "    route_check,\n",
    "    {  \n",
    "        \"Accepted\": END,\n",
    "        \"Rejected + Feedback\": \"reader_ocr_agent\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"spellchecker_agent\", \"extractor_agent\")\n",
    "workflow.add_edge(\"spellchecker_agent\", \"abstracter_agent\")\n",
    "workflow.add_edge(\"extractor_agent\", \"grade_calibrator_agent\")\n",
    "workflow.add_edge(\"abstracter_agent\", \"grade_calibrator_agent\")\n",
    "workflow.add_edge(\"grade_calibrator_agent\", \"evaluator_agent\")\n",
    "workflow.add_edge(\"evaluator_agent\", \"aggregator_agent\")\n",
    "workflow.add_edge(\"aggregator_agent\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "def run_langgraph_chat(initial_state=None):\n",
    "    print(\"ü§ñ Multi-Agent System Summary For Primary School Students\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Commands: 'exit', 'clear' (STM), 'clear_all' (STM+LTM), 'mem_stats'\")\n",
    "\n",
    "    state = initial_state or create_initial_state()\n",
    "\n",
    "    # KH√îNG auto-invoke n·∫øu ƒë√£ c√≥ messages (tr√°nh ch√†o l·∫°i)\n",
    "    if not state.get(\"messages\"):\n",
    "        try:\n",
    "            state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\nü§ñ{state['current_agent']}: {last.content}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    while True:\n",
    "        if not state.get(\"needs_user_input\", True):\n",
    "            state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\nü§ñ{state['current_agent']}: {last.content}\")\n",
    "            mem = memory_manager.get_memory()\n",
    "            print(f\"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]\")\n",
    "            continue\n",
    "\n",
    "        user_input = input(\"\\nüë§ B·∫°n: \").strip()\n",
    "        memory_manager.add_message(\"user\", user_input)\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"tho√°t\"]:\n",
    "            print(\"üëã Bye MAS L·ªãch s·ª≠ chat ƒë√£ ƒë∆∞·ª£c l∆∞u.\")\n",
    "            break\n",
    "        if user_input.lower() in [\"clear\", \"x√≥a\", \"reset\"]:\n",
    "            memory_manager.clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"üßπ ƒê√£ x√≥a short-term memory. Long-term v·∫´n gi·ªØ.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"clear_all\", \"x√≥a_all\", \"reset_all\"]:\n",
    "            memory_manager.clear_memory(also_long_term=True)\n",
    "            state = create_initial_state()\n",
    "            print(\"üßπ ƒê√£ x√≥a c·∫£ short-term v√† long-term memory.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"mem_stats\", \"memory_stats\"]:\n",
    "            print(f\"üìä Long-term Memory: {long_term_memory.collection.count()} items\")\n",
    "            continue\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        print(f\"üë§: {user_input}\")\n",
    "        state[\"needs_user_input\"] = False\n",
    "def build_state_from_memory(user_id: str = \"default_user\", max_messages: int = 10):\n",
    "    mem = memory_manager.get_memory(user_id)\n",
    "    msgs = []\n",
    "    ctrl = {\"tho√°t\",\"exit\",\"quit\",\"x√≥a\",\"clear\",\"reset\",\"clear_all\",\"x√≥a_all\",\"reset_all\"}\n",
    "    for m in mem.conversation_history[-max_messages:]:\n",
    "        content = (m.get(\"content\") or \"\").strip()\n",
    "        if content.lower() in ctrl:\n",
    "            continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role == \"user\":\n",
    "            msgs.append(HumanMessage(content=content))\n",
    "        else:\n",
    "            msgs.append(AIMessage(content=content))\n",
    "    needs_user_input = True if msgs and isinstance(msgs[-1], AIMessage) else False\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"current_agent\": \"coordinator_agent\",\n",
    "        \"needs_user_input\": needs_user_input,\n",
    "        \"conversation_stage\": \"planning\",\n",
    "    }\n",
    "def continue_chat_from_session(session_id: str, user_id: str = \"default_user\", replay_last_n: int = 20):\n",
    "    print(\"Previous chat history:\")\n",
    "    read_long_term_memory_by_session_id(\"session_20251028_140755\")\n",
    "    loaded = memory_manager.resume_session(session_id, user_id=user_id, replay_last_n=replay_last_n)\n",
    "    print(f\"Resumed {loaded} messages from long-term: {session_id}\")\n",
    "    initial_state = build_state_from_memory(user_id=user_id, max_messages=replay_last_n)\n",
    "    run_langgraph_chat(initial_state=initial_state)\n",
    "\n",
    "# run_langgraph_chat()\n",
    "# ho·∫∑c ti·∫øp n·ªëi t·ª´ 1 session c·ª• th·ªÉ:\n",
    "continue_chat_from_session(\"session_20251028_140755\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5473dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_long_term_memory_by_session_id(\"session_20251028_140755\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948436d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Khai b√°o State cho LangGraph\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n",
    "    current_agent: str\n",
    "    needs_user_input: bool\n",
    "    conversation_stage: Literal[\"greeting\", \"planning\", \"checking\", \"processing\", \"aggregator\", \"completed\"]\n",
    "    check: Literal[\"exactly\", \"not exactly\"] = Field(\n",
    "        description=\"Quy·∫øt ƒë·ªãnh xem vƒÉn b·∫£n ƒë√£ ƒë∆∞·ª£c t√≥m t·∫Øt ch√≠nh x√°c hay kh√¥ng.\",\n",
    "    )\n",
    "    feedback: str = Field(\n",
    "        description=\"N·∫øu vƒÉn b·∫£n kh√¥ng ch√≠nh x√°c, cung c·∫•p ph·∫£n h·ªìi ƒë·ªÉ c·∫£i thi·ªán n√≥.\",\n",
    "    )\n",
    "\n",
    "# H√†m ƒëi·ªÅu h∆∞·ªõng sau node coordinator\n",
    "def decide_next_agent(state: AgentState):\n",
    "    if state.get(\"needs_user_input\", False):\n",
    "        return \"END\"\n",
    "    return state.get(\"current_agent\", \"coordinator_agent\")\n",
    "\n",
    "def route_check(state: AgentState):\n",
    "    if state[\"check\"] == \"exactly\":\n",
    "        return \"Accepted\"\n",
    "    elif state[\"check\"] == \"not exactly\":\n",
    "        state[\"retry_count\"] = state.get(\"retry_count\", 0) + 1\n",
    "        if state[\"retry_count\"] > 3:\n",
    "            return \"T·ª´ ch·ªëi v√† cung c·∫•p ph·∫£n h·ªìi.\"\n",
    "        return \"T·ª´ ch·ªëi v√† cung c·∫•p ph·∫£n h·ªìi.\"\n",
    "    \n",
    "# Build ƒë·ªì th·ªã LangGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"coordinator_agent\", Coordinator_Agent.coordinator_agent)\n",
    "workflow.add_node(\"reader_ocr_agent\", OCR_Agent.ocr_agent)\n",
    "workflow.add_node(\"spellchecker_agent\", SpellChecker_Agent.spellchecker_agent)\n",
    "workflow.add_node(\"extractor_agent\", Extractor_Agent.extractor_agent)\n",
    "workflow.add_node(\"abstracter_agent\", Abstracter_Agent.abstracter_agent)\n",
    "workflow.add_node(\"grade_calibrator_agent\", GradeCalibrator_Agent.grade_calibrator_agent)\n",
    "workflow.add_node(\"evaluator_agent\", Evaluator_Agent.evaluator_agent)\n",
    "workflow.add_node(\"aggregator_agent\", Aggregator_Agent.aggregator_agent)\n",
    "\n",
    "workflow.set_entry_point(\"coordinator_agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator_agent\",\n",
    "    decide_next_agent,\n",
    "    {\n",
    "        \"reader_ocr_agent\": \"reader_ocr_agent\",\n",
    "        \"spellchecker_agent\": \"spellchecker_agent\",\n",
    "        \"extractor_agent\": \"extractor_agent\",\n",
    "        \"abstracter_agent\": \"abstracter_agent\",\n",
    "        \"grade_calibrator_agent\": \"grade_calibrator_agent\",\n",
    "        \"evaluator_agent\": \"evaluator_agent\",\n",
    "        \"aggregator_agent\": \"aggregator_agent\",\n",
    "        \"coordinator_agent\": \"coordinator_agent\",\n",
    "        \"END\": END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"reader_ocr_agent\", \"spellchecker_agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"spellchecker_agent\",\n",
    "    route_check,\n",
    "    {  \n",
    "        \"Accepted\": END,\n",
    "        \"Rejected + Feedback\": \"reader_ocr_agent\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"spellchecker_agent\", \"extractor_agent\")\n",
    "workflow.add_edge(\"spellchecker_agent\", \"abstracter_agent\")\n",
    "workflow.add_edge(\"extractor_agent\", \"grade_calibrator_agent\")\n",
    "workflow.add_edge(\"abstracter_agent\", \"grade_calibrator_agent\")\n",
    "workflow.add_edge(\"grade_calibrator_agent\", \"evaluator_agent\")\n",
    "workflow.add_edge(\"evaluator_agent\", \"aggregator_agent\")\n",
    "workflow.add_edge(\"aggregator_agent\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "def run_langgraph_chat(initial_state=None):\n",
    "    print(\"ü§ñ Multi-Agent System Summary For Primary School Students\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Commands: 'exit', 'clear' (STM), 'clear_all' (STM+LTM), 'mem_stats'\")\n",
    "\n",
    "    state = initial_state or create_initial_state()\n",
    "\n",
    "    # KH√îNG auto-invoke n·∫øu ƒë√£ c√≥ messages (tr√°nh ch√†o l·∫°i)\n",
    "    if not state.get(\"messages\"):\n",
    "        try:\n",
    "            state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\nü§ñ{state['current_agent']}: {last.content}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    while True:\n",
    "        if not state.get(\"needs_user_input\", True):\n",
    "            state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\nü§ñ{state['current_agent']}: {last.content}\")\n",
    "            mem = memory_manager.get_memory()\n",
    "            print(f\"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]\")\n",
    "            continue\n",
    "\n",
    "        user_input = input(\"\\nüë§ B·∫°n: \").strip()\n",
    "        memory_manager.add_message(\"user\", user_input)\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"tho√°t\"]:\n",
    "            print(\"üëã Bye MAS L·ªãch s·ª≠ chat ƒë√£ ƒë∆∞·ª£c l∆∞u.\")\n",
    "            break\n",
    "        if user_input.lower() in [\"clear\", \"x√≥a\", \"reset\"]:\n",
    "            memory_manager.clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"üßπ ƒê√£ x√≥a short-term memory. Long-term v·∫´n gi·ªØ.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"clear_all\", \"x√≥a_all\", \"reset_all\"]:\n",
    "            memory_manager.clear_memory(also_long_term=True)\n",
    "            state = create_initial_state()\n",
    "            print(\"üßπ ƒê√£ x√≥a c·∫£ short-term v√† long-term memory.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"mem_stats\", \"memory_stats\"]:\n",
    "            print(f\"üìä Long-term Memory: {long_term_memory.collection.count()} items\")\n",
    "            continue\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        print(f\"üë§: {user_input}\")\n",
    "        state[\"needs_user_input\"] = False\n",
    "def build_state_from_memory(user_id: str = \"default_user\", max_messages: int = 10):\n",
    "    mem = memory_manager.get_memory(user_id)\n",
    "    msgs = []\n",
    "    ctrl = {\"tho√°t\",\"exit\",\"quit\",\"x√≥a\",\"clear\",\"reset\",\"clear_all\",\"x√≥a_all\",\"reset_all\"}\n",
    "    for m in mem.conversation_history[-max_messages:]:\n",
    "        content = (m.get(\"content\") or \"\").strip()\n",
    "        if content.lower() in ctrl:\n",
    "            continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role == \"user\":\n",
    "            msgs.append(HumanMessage(content=content))\n",
    "        else:\n",
    "            msgs.append(AIMessage(content=content))\n",
    "    needs_user_input = True if msgs and isinstance(msgs[-1], AIMessage) else False\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"current_agent\": \"coordinator_agent\",\n",
    "        \"needs_user_input\": needs_user_input,\n",
    "        \"conversation_stage\": \"planning\",\n",
    "    }\n",
    "def continue_chat_from_session(session_id: str, user_id: str = \"default_user\", replay_last_n: int = 20):\n",
    "    print(\"Previous chat history:\")\n",
    "    read_long_term_memory_by_session_id(\"session_20251028_145534\")\n",
    "    loaded = memory_manager.resume_session(session_id, user_id=user_id, replay_last_n=replay_last_n)\n",
    "    print(f\"Resumed {loaded} messages from long-term: {session_id}\")\n",
    "    initial_state = build_state_from_memory(user_id=user_id, max_messages=replay_last_n)\n",
    "    run_langgraph_chat(initial_state=initial_state)\n",
    "\n",
    "# run_langgraph_chat()\n",
    "# ho·∫∑c ti·∫øp n·ªëi t·ª´ 1 session c·ª• th·ªÉ:\n",
    "continue_chat_from_session(\"session_20251028_145534\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f534c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9722da53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C·∫≠p nh·∫≠t AgentState v√† Workflow Graph\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n",
    "    current_agent: str\n",
    "    needs_user_input: bool\n",
    "    conversation_stage: Literal[\"greeting\", \"text_input\", \"summary_type\", \"processing\", \"completed\"]\n",
    "    original_text: str\n",
    "    summary_type: Literal[\"extract\", \"abstract\", None]\n",
    "    grade_level: int\n",
    "    processed_text: str\n",
    "    summary_result: str\n",
    "\n",
    "def create_initial_state() -> AgentState:\n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator_agent\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\",\n",
    "        \"original_text\": \"\",\n",
    "        \"summary_type\": None,\n",
    "        \"grade_level\": 0,\n",
    "        \"processed_text\": \"\",\n",
    "        \"summary_result\": \"\"\n",
    "    }\n",
    "\n",
    "# H√†m ƒëi·ªÅu h∆∞·ªõng sau node coordinator\n",
    "def decide_next_agent(state: AgentState):\n",
    "    if state.get(\"needs_user_input\", False):\n",
    "        return \"END\"\n",
    "    return state.get(\"current_agent\", \"coordinator_agent\")\n",
    "\n",
    "# Build ƒë·ªì th·ªã LangGraph v·ªõi workflow m·ªõi\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Th√™m c√°c nodes\n",
    "workflow.add_node(\"coordinator_agent\", Coordinator_Agent.coordinator_agent)\n",
    "workflow.add_node(\"reader_ocr_agent\", OCR_Agent.ocr_agent)\n",
    "workflow.add_node(\"spellchecker_agent\", SpellChecker_Agent.spellchecker_agent)\n",
    "workflow.add_node(\"extractor_agent\", Extractor_Agent.extractor_agent)\n",
    "workflow.add_node(\"abstracter_agent\", Abstracter_Agent.abstracter_agent)\n",
    "workflow.add_node(\"grade_calibrator_agent\", GradeCalibrator_Agent.grade_calibrator_agent)\n",
    "workflow.add_node(\"evaluator_agent\", Evaluator_Agent.evaluator_agent)\n",
    "workflow.add_node(\"aggregator_agent\", Aggregator_Agent.aggregator_agent)\n",
    "\n",
    "# Set entry point\n",
    "workflow.set_entry_point(\"coordinator_agent\")\n",
    "\n",
    "# Th√™m c√°c edges theo workflow m·ªõi\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator_agent\",\n",
    "    decide_next_agent,\n",
    "    {\n",
    "        \"reader_ocr_agent\": \"reader_ocr_agent\",\n",
    "        \"spellchecker_agent\": \"spellchecker_agent\", \n",
    "        \"extractor_agent\": \"extractor_agent\",\n",
    "        \"abstracter_agent\": \"abstracter_agent\",\n",
    "        \"grade_calibrator_agent\": \"grade_calibrator_agent\",\n",
    "        \"evaluator_agent\": \"evaluator_agent\",\n",
    "        \"aggregator_agent\": \"aggregator_agent\",\n",
    "        \"coordinator_agent\": \"coordinator_agent\",\n",
    "        \"END\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Workflow tu·∫ßn t·ª±: OCR -> SpellChecker -> Extractor/Abstracter -> GradeCalibrator -> Evaluator -> Aggregator\n",
    "workflow.add_edge(\"reader_ocr_agent\", \"spellchecker_agent\")\n",
    "workflow.add_edge(\"spellchecker_agent\", \"extractor_agent\")\n",
    "workflow.add_edge(\"spellchecker_agent\", \"abstracter_agent\")\n",
    "workflow.add_edge(\"extractor_agent\", \"grade_calibrator_agent\")\n",
    "workflow.add_edge(\"abstracter_agent\", \"grade_calibrator_agent\")\n",
    "workflow.add_edge(\"grade_calibrator_agent\", \"evaluator_agent\")\n",
    "workflow.add_edge(\"evaluator_agent\", \"aggregator_agent\")\n",
    "workflow.add_edge(\"aggregator_agent\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "print(\"‚úÖ Workflow graph ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t v·ªõi lu·ªìng x·ª≠ l√Ω tu·∫ßn t·ª±!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6629f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_langgraph_chat(initial_state=None):\n",
    "    print(\"ü§ñ Multi-Agent System Summary For Primary School Students\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Commands: 'exit', 'clear' (STM), 'clear_all' (STM+LTM), 'mem_stats'\")\n",
    "\n",
    "    state = initial_state or create_initial_state()\n",
    "\n",
    "    # KH√îNG auto-invoke n·∫øu ƒë√£ c√≥ messages (tr√°nh ch√†o l·∫°i)\n",
    "    if not state.get(\"messages\"):\n",
    "        try:\n",
    "            state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\nü§ñ{state['current_agent']}: {last.content}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            pass\n",
    "\n",
    "    while True:\n",
    "        if not state.get(\"needs_user_input\", True):\n",
    "            try:\n",
    "                state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "                last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "                if last and isinstance(last, AIMessage):\n",
    "                    print(f\"\\nü§ñ{state['current_agent']}: {last.content}\")\n",
    "                mem = memory_manager.get_memory()\n",
    "                print(f\"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Error in processing: {e}\")\n",
    "                break\n",
    "\n",
    "        user_input = input(\"\\nüë§ B·∫°n: \").strip()\n",
    "        memory_manager.add_message(\"user\", user_input)\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"tho√°t\"]:\n",
    "            print(\"üëã Bye MAS L·ªãch s·ª≠ chat ƒë√£ ƒë∆∞·ª£c l∆∞u.\")\n",
    "            break\n",
    "        if user_input.lower() in [\"clear\", \"x√≥a\", \"reset\"]:\n",
    "            memory_manager.clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"üßπ ƒê√£ x√≥a short-term memory. Long-term v·∫´n gi·ªØ.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"clear_all\", \"x√≥a_all\", \"reset_all\"]:\n",
    "            memory_manager.clear_memory(also_long_term=True)\n",
    "            state = create_initial_state()\n",
    "            print(\"üßπ ƒê√£ x√≥a c·∫£ short-term v√† long-term memory.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"mem_stats\", \"memory_stats\"]:\n",
    "            print(f\"üìä Long-term Memory: {long_term_memory.collection.count()} items\")\n",
    "            continue\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        print(f\"üë§: {user_input}\")\n",
    "        state[\"needs_user_input\"] = False\n",
    "\n",
    "def build_state_from_memory(user_id: str = \"default_user\", max_messages: int = 10):\n",
    "    mem = memory_manager.get_memory(user_id)\n",
    "    msgs = []\n",
    "    ctrl = {\"tho√°t\",\"exit\",\"quit\",\"x√≥a\",\"clear\",\"reset\",\"clear_all\",\"x√≥a_all\",\"reset_all\"}\n",
    "    for m in mem.conversation_history[-max_messages:]:\n",
    "        content = (m.get(\"content\") or \"\").strip()\n",
    "        if content.lower() in ctrl:\n",
    "            continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role == \"user\":\n",
    "            msgs.append(HumanMessage(content=content))\n",
    "        else:\n",
    "            msgs.append(AIMessage(content=content))\n",
    "    needs_user_input = True if msgs and isinstance(msgs[-1], AIMessage) else False\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"current_agent\": \"coordinator_agent\",\n",
    "        \"needs_user_input\": needs_user_input,\n",
    "        \"conversation_stage\": \"greeting\",\n",
    "        \"original_text\": \"\",\n",
    "        \"summary_type\": None,\n",
    "        \"grade_level\": 0,\n",
    "        \"processed_text\": \"\",\n",
    "        \"summary_result\": \"\"\n",
    "    }\n",
    "\n",
    "def continue_chat_from_session(session_id: str, user_id: str = \"default_user\", replay_last_n: int = 20):\n",
    "    print(\"Previous chat history:\")\n",
    "    read_long_term_memory_by_session_id(session_id)\n",
    "    loaded = memory_manager.resume_session(session_id, user_id=user_id, replay_last_n=replay_last_n)\n",
    "    print(f\"Resumed {loaded} messages from long-term: {session_id}\")\n",
    "    initial_state = build_state_from_memory(user_id=user_id, max_messages=replay_last_n)\n",
    "    run_langgraph_chat(initial_state=initial_state)\n",
    "\n",
    "print(\"‚úÖ H·ªá th·ªëng MAS ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
