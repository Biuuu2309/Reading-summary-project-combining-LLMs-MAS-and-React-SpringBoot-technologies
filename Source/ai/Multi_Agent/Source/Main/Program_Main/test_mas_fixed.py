# Test há»‡ thá»‘ng MAS Ä‘Ã£ Ä‘Æ°á»£c sá»­a
from pathlib import Path
import sys

project_root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / 'Source' / 'ai').exists()), None)
if project_root and str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from dotenv import load_dotenv
from langchain_ollama import ChatOllama
from langgraph.graph import END, StateGraph
import operator
from Source.ai.Multi_Agent.Source.Main.Agents.Agents_Summary import Abstracter_Agent, Aggregator_Agent, Coordinator_Agent, Evaluator_Agent, Extractor_Agent, GradeCalibrator_Agent, OCR_Agent, SpellChecker_Agent
from typing import TypedDict, Annotated, List, Any, Literal
from langchain_core.messages import HumanMessage, AIMessage
from Source.ai.Multi_Agent.Source.Main.Memory.memory.memory import memory_manager

load_dotenv()

# Äá»‹nh nghÄ©a AgentState Ä‘Ãºng cÃ¡ch
class AgentState(TypedDict):
    messages: Annotated[List[Any], operator.add]
    current_agent: str
    needs_user_input: bool
    conversation_stage: Literal["greeting", "text_input", "summary_type", "processing", "completed"]
    original_text: str
    summary_type: Literal["extract", "abstract", None]
    grade_level: int
    processed_text: str
    summary_result: str

def create_initial_state() -> AgentState:
    return {
        "messages": [],
        "current_agent": "coordinator_agent",
        "needs_user_input": False,
        "conversation_stage": "greeting",
        "original_text": "",
        "summary_type": None,
        "grade_level": 0,
        "processed_text": "",
        "summary_result": ""
    }

# HÃ m Ä‘iá»u hÆ°á»›ng Ä‘Æ¡n giáº£n
def decide_next_agent(state: AgentState):
    if state.get("needs_user_input", False):
        return "END"
    return state.get("current_agent", "coordinator_agent")

# Táº¡o workflow graph má»›i
workflow = StateGraph(AgentState)

# ThÃªm cÃ¡c nodes
workflow.add_node("coordinator_agent", Coordinator_Agent.coordinator_agent)
workflow.add_node("reader_ocr_agent", OCR_Agent.ocr_agent)
workflow.add_node("spellchecker_agent", SpellChecker_Agent.spellchecker_agent)
workflow.add_node("extractor_agent", Extractor_Agent.extractor_agent)
workflow.add_node("abstracter_agent", Abstracter_Agent.abstracter_agent)
workflow.add_node("grade_calibrator_agent", GradeCalibrator_Agent.grade_calibrator_agent)
workflow.add_node("evaluator_agent", Evaluator_Agent.evaluator_agent)
workflow.add_node("aggregator_agent", Aggregator_Agent.aggregator_agent)

# Set entry point
workflow.set_entry_point("coordinator_agent")

# ThÃªm conditional edges
workflow.add_conditional_edges(
    "coordinator_agent",
    decide_next_agent,
    {
        "reader_ocr_agent": "reader_ocr_agent",
        "spellchecker_agent": "spellchecker_agent", 
        "extractor_agent": "extractor_agent",
        "abstracter_agent": "abstracter_agent",
        "grade_calibrator_agent": "grade_calibrator_agent",
        "evaluator_agent": "evaluator_agent",
        "aggregator_agent": "aggregator_agent",
        "coordinator_agent": "coordinator_agent",
        "END": END,
    },
)

# ThÃªm cÃ¡c edges tuáº§n tá»±
workflow.add_edge("reader_ocr_agent", "spellchecker_agent")
workflow.add_edge("spellchecker_agent", "extractor_agent")
workflow.add_edge("spellchecker_agent", "abstracter_agent")
workflow.add_edge("extractor_agent", "grade_calibrator_agent")
workflow.add_edge("abstracter_agent", "grade_calibrator_agent")
workflow.add_edge("grade_calibrator_agent", "evaluator_agent")
workflow.add_edge("evaluator_agent", "aggregator_agent")
workflow.add_edge("aggregator_agent", END)

# Compile workflow
app = workflow.compile()

def run_langgraph_chat(initial_state=None):
    print("ğŸ¤– Multi-Agent System Summary For Primary School Students")
    print("=" * 60)
    print("Commands: 'exit', 'clear' (STM), 'clear_all' (STM+LTM), 'mem_stats'")

    state = initial_state or create_initial_state()

    # KHÃ”NG auto-invoke náº¿u Ä‘Ã£ cÃ³ messages (trÃ¡nh chÃ o láº¡i)
    if not state.get("messages"):
        try:
            print("ğŸš€ Báº¯t Ä‘áº§u há»‡ thá»‘ng...")
            state = app.invoke(state, config={"recursion_limit": 50})
            last = state["messages"][-1] if state["messages"] else None
            if last and isinstance(last, AIMessage):
                print(f"\nğŸ¤–{state['current_agent']}: {last.content}")
        except Exception as e:
            print(f"Error: {e}")
            pass

    while True:
        if not state.get("needs_user_input", True):
            try:
                print(f"ğŸ”„ Äang xá»­ lÃ½ vá»›i {state['current_agent']}...")
                state = app.invoke(state, config={"recursion_limit": 50})
                last = state["messages"][-1] if state["messages"] else None
                if last and isinstance(last, AIMessage):
                    print(f"\nğŸ¤–{state['current_agent']}: {last.content}")
                mem = memory_manager.get_memory()
                print(f"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]")
                continue
            except Exception as e:
                print(f"Error in processing: {e}")
                break

        user_input = input("\nğŸ‘¤ Báº¡n: ").strip()
        memory_manager.add_message("user", user_input)

        if user_input.lower() in ["exit", "quit", "thoÃ¡t"]:
            print("ğŸ‘‹ Bye MAS Lá»‹ch sá»­ chat Ä‘Ã£ Ä‘Æ°á»£c lÆ°u.")
            break
        if user_input.lower() in ["clear", "xÃ³a", "reset"]:
            memory_manager.clear_memory()
            state = create_initial_state()
            print("ğŸ§¹ ÄÃ£ xÃ³a short-term memory. Long-term váº«n giá»¯.")
            continue
        if user_input.lower() in ["clear_all", "xÃ³a_all", "reset_all"]:
            memory_manager.clear_memory(also_long_term=True)
            state = create_initial_state()
            print("ğŸ§¹ ÄÃ£ xÃ³a cáº£ short-term vÃ  long-term memory.")
            continue
        if user_input.lower() in ["mem_stats", "memory_stats"]:
            print(f"ğŸ“Š Long-term Memory: {long_term_memory.collection.count()} items")
            continue

        state["messages"].append(HumanMessage(content=user_input))
        print(f"ğŸ‘¤: {user_input}")
        state["needs_user_input"] = False

if __name__ == "__main__":
    print("ğŸš€ Báº¯t Ä‘áº§u test há»‡ thá»‘ng MAS Ä‘Ã£ Ä‘Æ°á»£c sá»­a...")
    run_langgraph_chat()
