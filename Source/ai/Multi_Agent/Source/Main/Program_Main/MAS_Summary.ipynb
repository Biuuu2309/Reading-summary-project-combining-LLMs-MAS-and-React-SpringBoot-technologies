{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "887a225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure repository root (with 'Source/ai') is on sys.path\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "project_root = next((p for p in [Path.cwd(), *Path.cwd().parents] if (p / 'Source' / 'ai').exists()), None)\n",
    "if project_root and str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain.tools import Tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "import operator\n",
    "import requests\n",
    "from Source.ai.Multi_Agent.Source.Main.Tools import poem_tools, sentiment_tools, travel_tools, weather_tools\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_1 import Coordinator_Agent_1, Flight_Agent_1, Hotel_Agent_1, Travel_Agent_1\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_2 import Coordinator_Agent_2, Flight_Agent_2, Hotel_Agent_2, Travel_Agent_2\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_3 import Coordinator_Agent_3, Flight_Agent_3, Hotel_Agent_3, Travel_Agent_3, Aggregator_Agent_3\n",
    "from Source.ai.Multi_Agent.Source.Main.Agents.Agents_Summary import Abstracter_Agent, Aggregator_Agent, Coordinator_Agent, Evaluator_Agent, Extractor_Agent, GradeCalibrator_Agent, OCR_Agent, SpellChecker_Agent\n",
    "from typing import TypedDict, Annotated, List, Any, Dict, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.memory import memory_manager\n",
    "from Source.ai.Multi_Agent.Source.Main.Memory.memory.long_term_memory import long_term_memory\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import uuid\n",
    "import os\n",
    "#from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1e42904",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(model=\"llama3:8b\") # <-- S·ª≠ d·ª•ng model b·∫°n ƒë√£ k√©o v·ªÅ, v√≠ d·ª• \"llama3\", \"mistral\"\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    messages: Annotated[List[str], operator.add]\n",
    "    \n",
    "prompt = hub.pull(\"hwchase17/react\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea45d564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New session started: session_20251028_105421\n"
     ]
    }
   ],
   "source": [
    "def new_session(user_id: str = \"default_user\", clear_history: bool = True, keep_preferences: bool = True, auto_continue: bool = False, replay_last_n: int = 20) -> str:\n",
    "    sid = memory_manager.start_new_session(user_id=user_id, clear_history=clear_history, keep_preferences=keep_preferences)\n",
    "    print(f\"New session started: {sid}\")\n",
    "    if auto_continue:\n",
    "        initial_state = build_state_from_memory(user_id=user_id, max_messages=replay_last_n)\n",
    "        run_langgraph_chat(initial_state=initial_state)\n",
    "    return sid\n",
    "\n",
    "sid = new_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f03660b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['q', 'session_20250925_130323', 'session_20250925_144950', 'session_20250925_150303', 'session_20250925_151001', 'session_20250927_162902', 'session_20250927_164507', 'session_20250928_092221', 'session_20250928_154914', 'session_20250928_155638', 'session_20251001_160456', 'session_20251002_093329', 'session_20251002_110113', 'session_20251002_143156']\n"
     ]
    }
   ],
   "source": [
    "all_items = long_term_memory.collection.get(include=[\"metadatas\"])\n",
    "session_ids = sorted({m.get(\"session_id\") for m in all_items[\"metadatas\"] if m})\n",
    "print(session_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "578789a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes wired: aggregator added between specialist agents and coordinator.\n"
     ]
    }
   ],
   "source": [
    "def create_initial_state() -> AgentState:\n",
    "    return {\n",
    "        \"messages\": [],\n",
    "        \"current_agent\": \"coordinator\",\n",
    "        \"needs_user_input\": False,\n",
    "        \"conversation_stage\": \"greeting\",\n",
    "    }\n",
    "state = create_initial_state()\n",
    "try:\n",
    "    state = app.invoke(state, config={\"recursion_limit\": 20})\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"Nodes wired: aggregator added between specialist agents and coordinator.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91e4eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_long_term_memory_by_session_id(session_id: str):\n",
    "    col = long_term_memory.collection\n",
    "    all_items = col.get(include=[\"documents\",\"metadatas\"])\n",
    "    for doc, meta in zip(all_items[\"documents\"], all_items[\"metadatas\"]):\n",
    "        if meta.get(\"session_id\") == session_id:\n",
    "            print(meta.get(\"timestamp\"), meta.get(\"session_id\"), meta.get(\"role\"), \":\", doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66fd543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous chat history:\n",
      "Resumed 0 messages from long-term: session_20251028_105421\n",
      "ü§ñ Multi-Agent System Summary For Primary School Students\n",
      "============================================================\n",
      "Commands: 'exit', 'clear' (STM), 'clear_all' (STM+LTM), 'mem_stats'\n",
      "\n",
      "ü§ñreader_ocr_agent: Xin ch√†o! T√¥i l√† tr·ª£ l√Ω x∆∞·ªüng t√≥m t·∫Øt th√¥ng minh theo kh·ªëi l·ªõp. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?\n",
      "üë§: T√¥i mu·ªën t√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát cho l·ªõp 3\n",
      "\n",
      "ü§ñreader_ocr_agent: R√µ r√†ng! B·∫°n mu·ªën t√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát cho l·ªõp 3, ƒë√∫ng kh√¥ng?\n",
      "\n",
      "Vui m·ª´ng! T√¥i s·∫Ω gi√∫p b·∫°n th·ª±c hi·ªán ƒëi·ªÅu ƒë√≥.\n",
      "\n",
      "VƒÉn b·∫£n c·ªßa b·∫°n c√≥ th·ªÉ ƒë∆∞·ª£c ƒë∆∞a l√™n h√¨nh ·∫£nh/PDF hay l√† text? (You can upload the file/image or type in the text)\n",
      "   [Memory: 4 msgs, 0 prefs]\n",
      "üë§: VƒÉn b·∫£n c·ªßa t√¥i nh∆∞ sau: Ng√†y khai tr∆∞·ªùng ƒë√£ ƒë·∫øn. S√°ng s·ªõm, m·∫π m·ªõi g·ªçi m·ªôt c√¢u m√† t√¥i ƒë√£ v√πng d·∫≠y, kh√°c h·∫≥n m·ªçi ng√†y. Lo√°ng m·ªôt c√°i, t√¥i ƒë√£ chu·∫©n b·ªã xong m·ªçi th·ª©. B·ªë ng·∫°c nhi√™n nh√¨n t√¥i, c√≤n m·∫π c∆∞·ªùi t·ªßm t·ªâm. T√¥i r√≠u r√≠t: ‚ÄúCon mu·ªën ƒë·∫øn s·ªõm nh·∫•t l·ªõp.‚Äù T√¥i h√°o h·ª©c t∆∞·ªüng t∆∞·ª£ng ra c·∫£nh m√¨nh ƒë·∫øn ƒë·∫ßu ti√™n, c·∫•t ti·∫øng ch√†o th·∫≠t to nh·ªØng b·∫°n ƒë·∫øn sau. Nh∆∞ng v·ª´a ƒë·∫øn c·ªïng tr∆∞·ªùng, t√¥i ƒë√£ th·∫•y m·∫•y b·∫°n c√πng l·ªõp ƒëang r√≠u r√≠t n√≥i c∆∞·ªùi ·ªü trong s√¢n. Th√¨ ra, kh√¥ng ch·ªâ m√¨nh t√¥i mu·ªën ƒë·∫øn s·ªõm nh·∫•t. T√¥i ch√†o m·∫π, ch·∫°y √†o v√†o c√πng c√°c b·∫°n. Ch√∫ng t√¥i tranh nhau k·ªÉ v·ªÅ chuy·ªán ng√†y h√®. Ngay c·∫°nh ch√∫ng t√¥i, m·∫•y em l·ªõp 1 ƒëang r·ª•t r√® n√≠u ch·∫∑t tay b·ªë m·∫π, th·∫≠t gi·ªëng t√¥i nƒÉm ngo√°i. Tr∆∞·ªõc c√°c em, t√¥i c·∫£m th·∫•y m√¨nh l·ªõn l·∫Øm. T√¥i ƒë√£ l√† h·ªçc sinh l·ªõp 2 r·ªìi c∆° m√†.\n",
      "\n",
      "ü§ñreader_ocr_agent: T√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát cho l·ªõp 3:\n",
      "\n",
      "\"Ng√†y khai tr∆∞·ªùng ƒë·∫øn, c√¥ b√© v√πng d·∫≠y v√† chu·∫©n b·ªã s·∫µn s√†ng. M·∫π c∆∞·ªùi t·ªßm t·ªâm, b·ªë ng·∫°c nhi√™n. C√¥ b√© r√≠u r√≠t: \"Con mu·ªën ƒë·∫øn s·ªõm nh·∫•t l·ªõp\". Khi ƒë·∫øn c·ªïng tr∆∞·ªùng, c√¥ b√© th·∫•y c√°c b·∫°n c√πng l·ªõp ƒëang ch∆°i. C√¥ b√© c·∫£m th·∫•y m√¨nh l·ªõn l·∫Øm, ƒë√£ l√† h·ªçc sinh l·ªõp 2 r·ªìi.\"\n",
      "\n",
      "K·∫øt qu·∫£ t√≥m t·∫Øt: 8/10 (ƒë·ªô \"d·ªÖ hi·ªÉu\" c·ªßa vƒÉn b·∫£n)\n",
      "\n",
      "Li·ªáu c√≥ c·∫ßn ƒëi·ªÅu ch·ªânh g√¨ kh√¥ng?\n",
      "   [Memory: 7 msgs, 0 prefs]\n",
      "üë§: Kh√¥ng\n",
      "\n",
      "ü§ñreader_ocr_agent: K·∫øt qu·∫£ t√≥m t·∫Øt ƒë√£ ƒë∆∞·ª£c x√°c nh·∫≠n.\n",
      "\n",
      "T√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát cho l·ªõp 3:\n",
      "\n",
      "\"Ng√†y khai tr∆∞·ªùng ƒë·∫øn, c√¥ b√© v√πng d·∫≠y v√† chu·∫©n b·ªã s·∫µn s√†ng. M·∫π c∆∞·ªùi t·ªßm t·ªâm, b·ªë ng·∫°c nhi√™n. C√¥ b√© r√≠u r√≠t: \"Con mu·ªën ƒë·∫øn s·ªõm nh·∫•t l·ªõp\". Khi ƒë·∫øn c·ªïng tr∆∞·ªùng, c√¥ b√© th·∫•y c√°c b·∫°n c√πng l·ªõp ƒëang ch∆°i. C√¥ b√© c·∫£m th·∫•y m√¨nh l·ªõn l·∫Øm, ƒë√£ l√† h·ªçc sinh l·ªõp 2 r·ªìi.\"\n",
      "\n",
      "K·∫øt qu·∫£ t√≥m t·∫Øt: 8/10 (ƒë·ªô \"d·ªÖ hi·ªÉu\" c·ªßa vƒÉn b·∫£n)\n",
      "\n",
      "N·∫øu c√≥ nhu c·∫ßu t√≥m t·∫Øt vƒÉn b·∫£n kh√°c, vui m·ª´ng! T√¥i s·∫Ω gi√∫p b·∫°n th·ª±c hi·ªán ƒëi·ªÅu ƒë√≥.\n",
      "   [Memory: 10 msgs, 0 prefs]\n",
      "üëã Bye MAS L·ªãch s·ª≠ chat ƒë√£ ƒë∆∞·ª£c l∆∞u.\n"
     ]
    }
   ],
   "source": [
    "# Khai b√°o State cho LangGraph\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[Any]\n",
    "    current_agent: str\n",
    "    needs_user_input: bool\n",
    "    conversation_stage: Literal[\"greeting\", \"reader_ocr\", \"spellchecker\", \"extractor\", \"abstracter\", \"grade_calibrator\", \"evaluator\", \"aggregator\", \"completed\"]\n",
    "    check: Literal[\"exactly\", \"not exactly\"] = Field(\n",
    "        description=\"Decide if the text is exactly the same as the original text.\",\n",
    "    )\n",
    "    feedback: str = Field(\n",
    "        description=\"If the text is not exactly the same as the original text, provide feedback on how to improve it.\",\n",
    "    )\n",
    "\n",
    "# H√†m ƒëi·ªÅu h∆∞·ªõng sau node coordinator\n",
    "def decide_next_agent(state: AgentState):\n",
    "    if state.get(\"needs_user_input\", False):\n",
    "        return \"END\"\n",
    "    return state.get(\"current_agent\", \"coordinator_agent\")\n",
    "\n",
    "def route_check(state: AgentState):\n",
    "    if state[\"check\"] == \"exactly\":\n",
    "        return \"Accepted\"\n",
    "    elif state[\"check\"] == \"not exactly\":\n",
    "        return \"Rejected + Feedback\"\n",
    "    \n",
    "# Build ƒë·ªì th·ªã LangGraph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"coordinator_agent\", Coordinator_Agent.coordinator_agent)\n",
    "workflow.add_node(\"reader_ocr_agent\", OCR_Agent.ocr_agent)\n",
    "workflow.add_node(\"spellchecker_agent\", SpellChecker_Agent.spellchecker_agent)\n",
    "workflow.add_node(\"extractor_agent\", Extractor_Agent.extractor_agent)\n",
    "workflow.add_node(\"abstracter_agent\", Abstracter_Agent.abstracter_agent)\n",
    "workflow.add_node(\"grade_calibrator_agent\", GradeCalibrator_Agent.grade_calibrator_agent)\n",
    "workflow.add_node(\"evaluator_agent\", Evaluator_Agent.evaluator_agent)\n",
    "workflow.add_node(\"aggregator_agent\", Aggregator_Agent.aggregator_agent)\n",
    "\n",
    "workflow.set_entry_point(\"coordinator_agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"coordinator_agent\",\n",
    "    decide_next_agent,\n",
    "    {\n",
    "        \"reader_ocr_agent\": \"reader_ocr_agent\",\n",
    "        \"spellchecker_agent\": \"spellchecker_agent\",\n",
    "        \"extractor_agent\": \"extractor_agent\",\n",
    "        \"abstracter_agent\": \"abstracter_agent\",\n",
    "        \"grade_calibrator_agent\": \"grade_calibrator_agent\",\n",
    "        \"evaluator_agent\": \"evaluator_agent\",\n",
    "        \"aggregator_agent\": \"aggregator_agent\",\n",
    "        \"coordinator_agent\": \"coordinator_agent\",\n",
    "        \"END\": END,\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"reader_ocr_agent\", \"spellchecker_agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"spellchecker_agent\",\n",
    "    route_check,\n",
    "    {  \n",
    "        \"Accepted\": END,\n",
    "        \"Rejected + Feedback\": \"reader_ocr_agent\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"spellchecker_agent\", \"extractor_agent\")\n",
    "workflow.add_edge(\"spellchecker_agent\", \"abstracter_agent\")\n",
    "workflow.add_edge(\"extractor_agent\", \"grade_calibrator_agent\")\n",
    "workflow.add_edge(\"abstracter_agent\", \"grade_calibrator_agent\")\n",
    "workflow.add_edge(\"grade_calibrator_agent\", \"evaluator_agent\")\n",
    "workflow.add_edge(\"evaluator_agent\", \"aggregator_agent\")\n",
    "workflow.add_edge(\"aggregator_agent\", END)\n",
    "\n",
    "app = workflow.compile()\n",
    "\n",
    "def run_langgraph_chat(initial_state=None):\n",
    "    print(\"ü§ñ Multi-Agent System Summary For Primary School Students\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Commands: 'exit', 'clear' (STM), 'clear_all' (STM+LTM), 'mem_stats'\")\n",
    "\n",
    "    state = initial_state or create_initial_state()\n",
    "\n",
    "    # KH√îNG auto-invoke n·∫øu ƒë√£ c√≥ messages (tr√°nh ch√†o l·∫°i)\n",
    "    if not state.get(\"messages\"):\n",
    "        try:\n",
    "            state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\nü§ñ{state['current_agent']}: {last.content}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    while True:\n",
    "        if not state.get(\"needs_user_input\", True):\n",
    "            state = app.invoke(state, config={\"recursion_limit\": 50})\n",
    "            last = state[\"messages\"][-1] if state[\"messages\"] else None\n",
    "            if last and isinstance(last, AIMessage):\n",
    "                print(f\"\\nü§ñ{state['current_agent']}: {last.content}\")\n",
    "            mem = memory_manager.get_memory()\n",
    "            print(f\"   [Memory: {len(mem.conversation_history)} msgs, {len(mem.user_preferences)} prefs]\")\n",
    "            continue\n",
    "\n",
    "        user_input = input(\"\\nüë§ B·∫°n: \").strip()\n",
    "        memory_manager.add_message(\"user\", user_input)\n",
    "\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"tho√°t\"]:\n",
    "            print(\"üëã Bye MAS L·ªãch s·ª≠ chat ƒë√£ ƒë∆∞·ª£c l∆∞u.\")\n",
    "            break\n",
    "        if user_input.lower() in [\"clear\", \"x√≥a\", \"reset\"]:\n",
    "            memory_manager.clear_memory()\n",
    "            state = create_initial_state()\n",
    "            print(\"üßπ ƒê√£ x√≥a short-term memory. Long-term v·∫´n gi·ªØ.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"clear_all\", \"x√≥a_all\", \"reset_all\"]:\n",
    "            memory_manager.clear_memory(also_long_term=True)\n",
    "            state = create_initial_state()\n",
    "            print(\"üßπ ƒê√£ x√≥a c·∫£ short-term v√† long-term memory.\")\n",
    "            continue\n",
    "        if user_input.lower() in [\"mem_stats\", \"memory_stats\"]:\n",
    "            print(f\"üìä Long-term Memory: {long_term_memory.collection.count()} items\")\n",
    "            continue\n",
    "\n",
    "        state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "        print(f\"üë§: {user_input}\")\n",
    "        state[\"needs_user_input\"] = False\n",
    "def build_state_from_memory(user_id: str = \"default_user\", max_messages: int = 10):\n",
    "    mem = memory_manager.get_memory(user_id)\n",
    "    msgs = []\n",
    "    ctrl = {\"tho√°t\",\"exit\",\"quit\",\"x√≥a\",\"clear\",\"reset\",\"clear_all\",\"x√≥a_all\",\"reset_all\"}\n",
    "    for m in mem.conversation_history[-max_messages:]:\n",
    "        content = (m.get(\"content\") or \"\").strip()\n",
    "        if content.lower() in ctrl:\n",
    "            continue\n",
    "        role = (m.get(\"role\") or \"\").lower()\n",
    "        if role == \"user\":\n",
    "            msgs.append(HumanMessage(content=content))\n",
    "        else:\n",
    "            msgs.append(AIMessage(content=content))\n",
    "    needs_user_input = True if msgs and isinstance(msgs[-1], AIMessage) else False\n",
    "    return {\n",
    "        \"messages\": msgs,\n",
    "        \"current_agent\": \"coordinator_agent\",\n",
    "        \"needs_user_input\": needs_user_input,\n",
    "        \"conversation_stage\": \"reader_ocr\",\n",
    "    }\n",
    "def continue_chat_from_session(session_id: str, user_id: str = \"default_user\", replay_last_n: int = 20):\n",
    "    print(\"Previous chat history:\")\n",
    "    read_long_term_memory_by_session_id(\"session_20251028_105421\")\n",
    "    loaded = memory_manager.resume_session(session_id, user_id=user_id, replay_last_n=replay_last_n)\n",
    "    print(f\"Resumed {loaded} messages from long-term: {session_id}\")\n",
    "    initial_state = build_state_from_memory(user_id=user_id, max_messages=replay_last_n)\n",
    "    run_langgraph_chat(initial_state=initial_state)\n",
    "\n",
    "# run_langgraph_chat()\n",
    "# ho·∫∑c ti·∫øp n·ªëi t·ª´ 1 session c·ª• th·ªÉ:\n",
    "continue_chat_from_session(\"session_20251028_105421\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5473dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-28T10:54:59.953644 session_20251028_105421 assistant : assistant: Xin ch√†o! T√¥i l√† tr·ª£ l√Ω x∆∞·ªüng t√≥m t·∫Øt th√¥ng minh theo kh·ªëi l·ªõp. T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?\n",
      "2025-10-28T10:55:38.427037 session_20251028_105421 user : user: T√¥i mu·ªën t√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát cho l·ªõp 3\n",
      "2025-10-28T10:55:38.856110 session_20251028_105421 user : user: T√¥i mu·ªën t√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát cho l·ªõp 3\n",
      "2025-10-28T10:56:18.961364 session_20251028_105421 assistant : assistant: R√µ r√†ng! B·∫°n mu·ªën t√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát cho l·ªõp 3, ƒë√∫ng kh√¥ng?\n",
      "\n",
      "Vui m·ª´ng! T√¥i s·∫Ω gi√∫p b·∫°n th·ª±c hi·ªán ƒëi·ªÅu ƒë√≥.\n",
      "\n",
      "VƒÉn b·∫£n c·ªßa b·∫°n c√≥ th·ªÉ ƒë∆∞·ª£c ƒë∆∞a l√™n h√¨nh ·∫£nh/PDF hay l√† text? (You can upload the file/image or type in the text)\n",
      "2025-10-28T10:57:33.219459 session_20251028_105421 user : user: VƒÉn b·∫£n c·ªßa t√¥i nh∆∞ sau: Ng√†y khai tr∆∞·ªùng ƒë√£ ƒë·∫øn. S√°ng s·ªõm, m·∫π m·ªõi g·ªçi m·ªôt c√¢u m√† t√¥i ƒë√£ v√πng d·∫≠y, kh√°c h·∫≥n m·ªçi ng√†y. Lo√°ng m·ªôt c√°i, t√¥i ƒë√£ chu·∫©n b·ªã xong m·ªçi th·ª©. B·ªë ng·∫°c nhi√™n nh√¨n t√¥i, c√≤n m·∫π c∆∞·ªùi t·ªßm t·ªâm. T√¥i r√≠u r√≠t: ‚ÄúCon mu·ªën ƒë·∫øn s·ªõm nh·∫•t l·ªõp.‚Äù T√¥i h√°o h·ª©c t∆∞·ªüng t∆∞·ª£ng ra c·∫£nh m√¨nh ƒë·∫øn ƒë·∫ßu ti√™n, c·∫•t ti·∫øng ch√†o th·∫≠t to nh·ªØng b·∫°n ƒë·∫øn sau. Nh∆∞ng v·ª´a ƒë·∫øn c·ªïng tr∆∞·ªùng, t√¥i ƒë√£ th·∫•y m·∫•y b·∫°n c√πng l·ªõp ƒëang r√≠u r√≠t n√≥i c∆∞·ªùi ·ªü trong s√¢n. Th√¨ ra, kh√¥ng ch·ªâ m√¨nh t√¥i mu·ªën ƒë·∫øn s·ªõm nh·∫•t. T√¥i ch√†o m·∫π, ch·∫°y √†o v√†o c√πng c√°c b·∫°n. Ch√∫ng t√¥i tranh nhau k·ªÉ v·ªÅ chuy·ªán ng√†y h√®. Ngay c·∫°nh ch√∫ng t√¥i, m·∫•y em l·ªõp 1 ƒëang r·ª•t r√® n√≠u ch·∫∑t tay b·ªë m·∫π, th·∫≠t gi·ªëng t√¥i nƒÉm ngo√°i. Tr∆∞·ªõc c√°c em, t√¥i c·∫£m th·∫•y m√¨nh l·ªõn l·∫Øm. T√¥i ƒë√£ l√† h·ªçc sinh l·ªõp 2 r·ªìi c∆° m√†.\n",
      "2025-10-28T10:57:33.774179 session_20251028_105421 user : user: VƒÉn b·∫£n c·ªßa t√¥i nh∆∞ sau: Ng√†y khai tr∆∞·ªùng ƒë√£ ƒë·∫øn. S√°ng s·ªõm, m·∫π m·ªõi g·ªçi m·ªôt c√¢u m√† t√¥i ƒë√£ v√πng d·∫≠y, kh√°c h·∫≥n m·ªçi ng√†y. Lo√°ng m·ªôt c√°i, t√¥i ƒë√£ chu·∫©n b·ªã xong m·ªçi th·ª©. B·ªë ng·∫°c nhi√™n nh√¨n t√¥i, c√≤n m·∫π c∆∞·ªùi t·ªßm t·ªâm. T√¥i r√≠u r√≠t: ‚ÄúCon mu·ªën ƒë·∫øn s·ªõm nh·∫•t l·ªõp.‚Äù T√¥i h√°o h·ª©c t∆∞·ªüng t∆∞·ª£ng ra c·∫£nh m√¨nh ƒë·∫øn ƒë·∫ßu ti√™n, c·∫•t ti·∫øng ch√†o th·∫≠t to nh·ªØng b·∫°n ƒë·∫øn sau. Nh∆∞ng v·ª´a ƒë·∫øn c·ªïng tr∆∞·ªùng, t√¥i ƒë√£ th·∫•y m·∫•y b·∫°n c√πng l·ªõp ƒëang r√≠u r√≠t n√≥i c∆∞·ªùi ·ªü trong s√¢n. Th√¨ ra, kh√¥ng ch·ªâ m√¨nh t√¥i mu·ªën ƒë·∫øn s·ªõm nh·∫•t. T√¥i ch√†o m·∫π, ch·∫°y √†o v√†o c√πng c√°c b·∫°n. Ch√∫ng t√¥i tranh nhau k·ªÉ v·ªÅ chuy·ªán ng√†y h√®. Ngay c·∫°nh ch√∫ng t√¥i, m·∫•y em l·ªõp 1 ƒëang r·ª•t r√® n√≠u ch·∫∑t tay b·ªë m·∫π, th·∫≠t gi·ªëng t√¥i nƒÉm ngo√°i. Tr∆∞·ªõc c√°c em, t√¥i c·∫£m th·∫•y m√¨nh l·ªõn l·∫Øm. T√¥i ƒë√£ l√† h·ªçc sinh l·ªõp 2 r·ªìi c∆° m√†.\n",
      "2025-10-28T10:58:44.670736 session_20251028_105421 assistant : assistant: T√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát cho l·ªõp 3:\n",
      "\n",
      "\"Ng√†y khai tr∆∞·ªùng ƒë·∫øn, c√¥ b√© v√πng d·∫≠y v√† chu·∫©n b·ªã s·∫µn s√†ng. M·∫π c∆∞·ªùi t·ªßm t·ªâm, b·ªë ng·∫°c nhi√™n. C√¥ b√© r√≠u r√≠t: \"Con mu·ªën ƒë·∫øn s·ªõm nh·∫•t l·ªõp\". Khi ƒë·∫øn c·ªïng tr∆∞·ªùng, c√¥ b√© th·∫•y c√°c b·∫°n c√πng l·ªõp ƒëang ch∆°i. C√¥ b√© c·∫£m th·∫•y m√¨nh l·ªõn l·∫Øm, ƒë√£ l√† h·ªçc sinh l·ªõp 2 r·ªìi.\"\n",
      "\n",
      "K·∫øt qu·∫£ t√≥m t·∫Øt: 8/10 (ƒë·ªô \"d·ªÖ hi·ªÉu\" c·ªßa vƒÉn b·∫£n)\n",
      "\n",
      "Li·ªáu c√≥ c·∫ßn ƒëi·ªÅu ch·ªânh g√¨ kh√¥ng?\n",
      "2025-10-28T11:00:47.397452 session_20251028_105421 user : user: Kh√¥ng\n",
      "2025-10-28T11:00:48.058970 session_20251028_105421 user : user: Kh√¥ng\n",
      "2025-10-28T11:01:23.352294 session_20251028_105421 assistant : assistant: K·∫øt qu·∫£ t√≥m t·∫Øt ƒë√£ ƒë∆∞·ª£c x√°c nh·∫≠n.\n",
      "\n",
      "T√≥m t·∫Øt vƒÉn b·∫£n ti·∫øng Vi·ªát cho l·ªõp 3:\n",
      "\n",
      "\"Ng√†y khai tr∆∞·ªùng ƒë·∫øn, c√¥ b√© v√πng d·∫≠y v√† chu·∫©n b·ªã s·∫µn s√†ng. M·∫π c∆∞·ªùi t·ªßm t·ªâm, b·ªë ng·∫°c nhi√™n. C√¥ b√© r√≠u r√≠t: \"Con mu·ªën ƒë·∫øn s·ªõm nh·∫•t l·ªõp\". Khi ƒë·∫øn c·ªïng tr∆∞·ªùng, c√¥ b√© th·∫•y c√°c b·∫°n c√πng l·ªõp ƒëang ch∆°i. C√¥ b√© c·∫£m th·∫•y m√¨nh l·ªõn l·∫Øm, ƒë√£ l√† h·ªçc sinh l·ªõp 2 r·ªìi.\"\n",
      "\n",
      "K·∫øt qu·∫£ t√≥m t·∫Øt: 8/10 (ƒë·ªô \"d·ªÖ hi·ªÉu\" c·ªßa vƒÉn b·∫£n)\n",
      "\n",
      "N·∫øu c√≥ nhu c·∫ßu t√≥m t·∫Øt vƒÉn b·∫£n kh√°c, vui m·ª´ng! T√¥i s·∫Ω gi√∫p b·∫°n th·ª±c hi·ªán ƒëi·ªÅu ƒë√≥.\n",
      "2025-10-28T11:01:40.870120 session_20251028_105421 user : user: tho√°t\n"
     ]
    }
   ],
   "source": [
    "read_long_term_memory_by_session_id(\"session_20251028_105421\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb405af9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'Source.ai.Multi_Agent.Source.Main.Agents.Agents_Summary.Coordinator_Agent' has no attribute 'coordinator_tool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m coordinator_agent \u001b[38;5;241m=\u001b[39m create_react_agent(llm, [\u001b[43mCoordinator_Agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoordinator_tool\u001b[49m], prompt) \n\u001b[0;32m      2\u001b[0m coordinator_agent_executor \u001b[38;5;241m=\u001b[39m AgentExecutor(agent\u001b[38;5;241m=\u001b[39mcoordinator_agent, tools\u001b[38;5;241m=\u001b[39m[Coordinator_Agent\u001b[38;5;241m.\u001b[39mcoordinator_tool], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, handle_parsing_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_coordinator_agent\u001b[39m(state: AgentState):\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'Source.ai.Multi_Agent.Source.Main.Agents.Agents_Summary.Coordinator_Agent' has no attribute 'coordinator_tool'"
     ]
    }
   ],
   "source": [
    "coordinator_agent = create_react_agent(llm, [Coordinator_Agent.coordinator_tool], prompt) \n",
    "coordinator_agent_executor = AgentExecutor(agent=coordinator_agent, tools=[Coordinator_Agent.coordinator_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_coordinator_agent(state: AgentState):\n",
    "    result = coordinator_agent_executor.invoke({\"input\": f\"H√£y t·∫°o b·∫£n t√≥m t·∫Øt cho b√†i vi·∫øt sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"B·∫£n t√≥m t·∫Øt: {result['output']}\"]}\n",
    "\n",
    "abstracter_agent = create_react_agent(llm, [Abstracter_Agent.abstracter_tool], prompt) \n",
    "abstracter_agent_executor = AgentExecutor(agent=abstracter_agent, tools=[Abstracter_Agent.abstracter_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_abstracter_agent(state: AgentState):\n",
    "    result = abstracter_agent_executor.invoke({\"input\": f\"H√£y t·∫°o b·∫£n t√≥m t·∫Øt tr√≠ch xu·∫•t t·ª´ b√†i vi·∫øt sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"B·∫£n t√≥m t·∫Øt tr√≠ch xu·∫•t: {result['output']}\"]}\n",
    "\n",
    "extractor_agent = create_react_agent(llm, [Extractor_Agent.extractor_tool], prompt) \n",
    "extractor_agent_executor = AgentExecutor(agent=extractor_agent, tools=[Extractor_Agent.extractor_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_extractor_agent(state: AgentState):\n",
    "    result = extractor_agent_executor.invoke({\"input\": f\"H√£y t√≥m t·∫Øt di·ªÖn gi·∫£i vƒÉn b·∫£n sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"T√≥m t·∫Øt di·ªÖn gi·∫£i vƒÉn b·∫£n: {result['output']}\"]}\n",
    "\n",
    "grade_calibrator_agent = create_react_agent(llm, [GradeCalibrator_Agent.grade_calibrator_tool], prompt) \n",
    "grade_calibrator_agent_executor = AgentExecutor(agent=grade_calibrator_agent, tools=[GradeCalibrator_Agent.grade_calibrator_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_grade_calibrator_agent(state: AgentState):\n",
    "    result = grade_calibrator_agent_executor.invoke({\"input\": f\"H√£y ƒëi·ªÅu ch·ªânh ƒë·ªô d√†i v√† t·ª´ v·ª±ng c·ªßa b·∫£n t√≥m t·∫Øt sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"VƒÉn b·∫£n ƒëi·ªÅu ch·ªânh: {result['output']}\"]}\n",
    "\n",
    "evaluator_agent = create_react_agent(llm, [Evaluator_Agent.evaluator_tool], prompt) \n",
    "evaluator_agent_executor = AgentExecutor(agent=evaluator_agent, tools=[Evaluator_Agent.evaluator_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_evaluator_agent(state: AgentState):\n",
    "    result = evaluator_agent_executor.invoke({\"input\": f\"H√£y ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng v√† ƒë∆∞a ra ƒëi·ªÉm s·ªë d·ª±a tr√™n ƒë·ªô d·ªÖ hi·ªÉu c·ªßa b·∫£n t√≥m t·∫Øt sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng: {result['output']}\"]}\n",
    "\n",
    "aggregator_agent = create_react_agent(llm, [Aggregator_Agent.aggregator_tool], prompt) \n",
    "aggregator_agent_executor = AgentExecutor(agent=aggregator_agent, tools=[Aggregator_Agent.aggregator_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_aggregator_agent(state: AgentState):\n",
    "    result = aggregator_agent_executor.invoke({\"input\": f\"H√£y t·ªïng h·ª£p t·∫•t c·∫£ c√°c b·∫£n t√≥m t·∫Øt sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"T·ªïng h·ª£p t√≥m t·∫Øt: {result['output']}\"]}\n",
    "\n",
    "ocr_agent = create_react_agent(llm, [OCR_Agent.ocr_tool], prompt) \n",
    "ocr_agent_executor = AgentExecutor(agent=ocr_agent, tools=[OCR_Agent.ocr_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_ocr_agent(state: AgentState):\n",
    "    result = ocr_agent_executor.invoke({\"input\": f\"H√£y tr√≠ch xu·∫•t vƒÉn b·∫£n t·ª´ h√¨nh ·∫£nh, file, vƒÉn b·∫£n sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"VƒÉn b·∫£n tr√≠ch xu·∫•t: {result['output']}\"]}\n",
    "\n",
    "spellchecker_agent = create_react_agent(llm, [SpellChecker_Agent.spellchecker_tool], prompt) \n",
    "spellchecker_agent_executor = AgentExecutor(agent=spellchecker_agent, tools=[SpellChecker_Agent.spellchecker_tool], verbose=True, handle_parsing_errors=True) \n",
    "\n",
    "def call_spellchecker_agent(state: AgentState):\n",
    "    result = spellchecker_agent_executor.invoke({\"input\": f\"H√£y ki·ªÉm tra v√† s·ª≠a l·ªói ch√≠nh t·∫£ c·ªßa vƒÉn b·∫£n sau: {state['input']}\"})\n",
    "    return {\"messages\": [f\"VƒÉn b·∫£n s·ª≠a l·ªói: {result['output']}\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7db26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(AgentState)\n",
    "\n",
    "graph_builder.add_node(\"coordinator_agent\", Coordinator_Agent.coordinator_agent)\n",
    "graph_builder.add_node(\"reader_ocr_agent\", OCR_Agent.ocr_agent)\n",
    "graph_builder.add_node(\"spellchecker_agent\", SpellChecker_Agent.spellchecker_agent)\n",
    "graph_builder.add_node(\"extractor_agent\", Extractor_Agent.extractor_agent)\n",
    "graph_builder.add_node(\"abstracter_agent\", Abstracter_Agent.abstracter_agent)\n",
    "graph_builder.add_node(\"grade_calibrator_agent\", GradeCalibrator_Agent.grade_calibrator_agent)\n",
    "graph_builder.add_node(\"evaluator_agent\", Evaluator_Agent.evaluator_agent)\n",
    "graph_builder.add_node(\"aggregator_agent\", Aggregator_Agent.aggregator_agent)\n",
    "\n",
    "graph_builder.set_entry_point(\"coordinator_agent\")\n",
    "\n",
    "graph_builder.add_edge(\"coordinator_agent\", \"reader_ocr_agent\")\n",
    "graph_builder.add_edge(\"reader_ocr_agent\", \"spellchecker_agent\")\n",
    "graph_builder.add_edge(\"spellchecker_agent\", \"extractor_agent\")\n",
    "graph_builder.add_edge(\"extractor_agent\", \"abstracter_agent\")\n",
    "graph_builder.add_edge(\"abstracter_agent\", \"grade_calibrator_agent\")\n",
    "graph_builder.add_edge(\"grade_calibrator_agent\", \"evaluator_agent\")\n",
    "graph_builder.add_edge(\"evaluator_agent\", \"aggregator_agent\")\n",
    "graph_builder.add_edge(\"aggregator_agent\", END)\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "input_test1 = \"T√≥m t·∫Øt b√†i vi·∫øt sau: Ng√†y khai tr∆∞·ªùng ƒë√£ ƒë·∫øn. S√°ng s·ªõm, m·∫π m·ªõi g·ªçi m·ªôt c√¢u m√† t√¥i ƒë√£ v√πng d·∫≠y, kh√°c h·∫≥n m·ªçi ng√†y. Lo√°ng m·ªôt c√°i, t√¥i ƒë√£ chu·∫©n b·ªã xong m·ªçi th·ª©. B·ªë ng·∫°c nhi√™n nh√¨n t√¥i, c√≤n m·∫π c∆∞·ªùi t·ªßm t·ªâm. T√¥i r√≠u r√≠t: ‚ÄúCon mu·ªën ƒë·∫øn s·ªõm nh·∫•t l·ªõp.‚Äù T√¥i h√°o h·ª©c t∆∞·ªüng t∆∞·ª£ng ra c·∫£nh m√¨nh ƒë·∫øn ƒë·∫ßu ti√™n, c·∫•t ti·∫øng ch√†o th·∫≠t to nh·ªØng b·∫°n ƒë·∫øn sau. Nh∆∞ng v·ª´a ƒë·∫øn c·ªïng tr∆∞·ªùng, t√¥i ƒë√£ th·∫•y m·∫•y b·∫°n c√πng l·ªõp ƒëang r√≠u r√≠t n√≥i c∆∞·ªùi ·ªü trong s√¢n. Th√¨ ra, kh√¥ng ch·ªâ m√¨nh t√¥i mu·ªën ƒë·∫øn s·ªõm nh·∫•t. T√¥i ch√†o m·∫π, ch·∫°y √†o v√†o c√πng c√°c b·∫°n. Ch√∫ng t√¥i tranh nhau k·ªÉ v·ªÅ chuy·ªán ng√†y h√®. Ngay c·∫°nh ch√∫ng t√¥i, m·∫•y em l·ªõp 1 ƒëang r·ª•t r√® n√≠u ch·∫∑t tay b·ªë m·∫π, th·∫≠t gi·ªëng t√¥i nƒÉm ngo√°i. Tr∆∞·ªõc c√°c em, t√¥i c·∫£m th·∫•y m√¨nh l·ªõn l·∫Øm. T√¥i ƒë√£ l√† h·ªçc sinh l·ªõp 2 r·ªìi c∆° m√†. \"\n",
    "\n",
    "final_state = graph.invoke({\"input\": input_test1})\n",
    "print(\"K·∫øt qu·∫£ cu·ªëi c√πng:\")\n",
    "for message in final_state[\"messages\"]:\n",
    "    print(\"- \", message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
