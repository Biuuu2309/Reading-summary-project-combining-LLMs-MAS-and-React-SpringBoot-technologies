from dotenv import load_dotenv
load_dotenv()

# from langchain_openai import ChatOpenAI # <-- DÃ²ng cÅ©, comment láº¡i
from langchain_community.chat_models import ChatOllama # <-- DÃ²ng má»›i
from langchain.agents import create_react_agent, AgentExecutor
from langchain import hub
from langchain.tools import Tool
from langgraph.graph import END, StateGraph
from typing import TypedDict, Annotated, List, Any, Dict, Literal
import operator
import requests
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from Source.ai.Multi_Agent.Source.Main.Memory.memory.memory import memory_manager
# Khá»Ÿi táº¡o model LLM Local tá»« Ollama
llm = ChatOllama(model="llama3:8b") # <-- Sá»­ dá»¥ng model báº¡n Ä‘Ã£ kÃ©o vá», vÃ­ dá»¥ "llama3", "mistral"
class AgentState(TypedDict):
    messages: Annotated[List[Any], operator.add]
    current_agent: str
    needs_user_input: bool
    conversation_stage: Literal["greeting", "text_input", "summary_type", "processing", "completed"]
    original_text: str
    summary_type: Literal["extract", "abstract", None]
    grade_level: int
    processed_text: str
    summary_result: str

AGGREGATOR_SYSTEM = """Báº¡n lÃ  Aggregator Agent chuyÃªn nghiá»‡p. Nhiá»‡m vá»¥:
1. Tá»•ng há»£p báº£n tÃ³m táº¯t cuá»‘i cÃ¹ng
2. ÄÆ°a ra káº¿t quáº£ hoÃ n chá»‰nh cho user
3. Há»i user Ä‘Ã¡nh giÃ¡ vá» há»‡ thá»‘ng"""

def aggregator_agent(state: AgentState):
    messages = state["messages"]
    memory = memory_manager.get_memory()
    summary_result = state.get("summary_result", "")
    summary_type = state.get("summary_type", "extract")
    grade_level = state.get("grade_level", 3)
    original_text = state.get("original_text", "")
    
    if not summary_result:
        response = AIMessage(content="KhÃ´ng cÃ³ báº£n tÃ³m táº¯t Ä‘á»ƒ tá»•ng há»£p.")
        memory.add_message("assistant", response.content)
        return {
            "messages": [response],
            "current_agent": "coordinator_agent",
            "needs_user_input": True,
            "conversation_stage": "text_input",
            "original_text": "",
            "summary_type": None,
            "grade_level": 0,
            "processed_text": "",
            "summary_result": "",
            "final_result": ""
        }
    
    # Táº¡o báº£n tÃ³m táº¯t cuá»‘i cÃ¹ng
    final_summary = f"""ðŸ“ **Báº¢N TÃ“M Táº®T CUá»I CÃ™NG**

**Loáº¡i tÃ³m táº¯t:** {summary_type.upper()}
**Khá»‘i lá»›p:** {grade_level}

**Ná»™i dung:**
{summary_result}

---

Báº£n tÃ³m táº¯t Ä‘Ã£ hoÃ n thÃ nh! Báº¡n cÃ³ hÃ i lÃ²ng vá»›i káº¿t quáº£ nÃ y khÃ´ng? HÃ£y Ä‘Ã¡nh giÃ¡ há»‡ thá»‘ng tá»« 1-10 Ä‘iá»ƒm."""
    
    response = AIMessage(content=final_summary)
    memory.add_message("assistant", response.content)
    
    return {
        "messages": [response],
        "current_agent": "coordinator_agent",
        "needs_user_input": False,  # KhÃ´ng cáº§n user input, sáº½ chuyá»ƒn vá» coordinator
        "conversation_stage": "processing",
        "original_text": original_text,
        "summary_type": summary_type,
        "grade_level": grade_level,
        "processed_text": state.get("processed_text", ""),
        "summary_result": summary_result,
        "final_result": final_summary  # Truyá»n káº¿t quáº£ cuá»‘i cÃ¹ng
    }
aggregator_tool = Tool(
    name="AggregatorAgent",
    func=aggregator_agent,
    description="Use this to aggregate a given text. Input must be a text."
)