from dotenv import load_dotenv
load_dotenv()

# from langchain_openai import ChatOpenAI # <-- DÃ²ng cÅ©, comment láº¡i
from langchain_community.chat_models import ChatOllama # <-- DÃ²ng má»›i
from langchain.agents import create_react_agent, AgentExecutor
from langchain import hub
from langchain.tools import Tool
from langgraph.graph import END, StateGraph
from typing import TypedDict, Annotated, List, Any, Dict, Literal
import operator
import requests
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from Source.ai.Multi_Agent.Source.Main.Memory.memory.memory import memory_manager

# Khá»Ÿi táº¡o model LLM Local tá»« Ollama
llm = ChatOllama(model="llama3:8b") # <-- Sá»­ dá»¥ng model báº¡n Ä‘Ã£ kÃ©o vá», vÃ­ dá»¥ "llama3", "mistral"
class AgentState(TypedDict):
    messages: Annotated[List[Any], operator.add]
    current_agent: str
    needs_user_input: bool
    conversation_stage: Literal["greeting", "text_input", "summary_type", "processing", "completed"]
    original_text: str
    summary_type: Literal["extract", "abstract", None]
    grade_level: int
    processed_text: str
    summary_result: str

COORDINATOR_SYSTEM = """Báº¡n lÃ  Coordinator Agent thÃ´ng minh giÃºp há»c sinh tiá»ƒu há»c tÃ³m táº¯t vÄƒn báº£n theo 2 cÃ¡ch (TRÃCH XUáº¤T vÃ  DIá»„N GIáº¢I) phÃ¹ há»£p vá»›i khá»‘i lá»›p (1-5).

Workflow cá»§a báº¡n:
1. GREETING: ChÃ o há»i vÃ  yÃªu cáº§u user cung cáº¥p vÄƒn báº£n
2. TEXT_INPUT: Nháº­n vÄƒn báº£n tá»« user vÃ  chuyá»ƒn cho OCR/SpellChecker Ä‘á»ƒ xá»­ lÃ½
3. SUMMARY_TYPE: Há»i user muá»‘n tÃ³m táº¯t TRÃCH XUáº¤T hay DIá»„N GIáº¢I vÃ  khá»‘i lá»›p nÃ o (1-5)
4. PROCESSING: PhÃ¢n cÃ´ng cho agent phÃ¹ há»£p (Extractor hoáº·c Abstracter)
5. COMPLETED: Tá»•ng há»£p káº¿t quáº£ vÃ  há»i Ä‘Ã¡nh giÃ¡ há»‡ thá»‘ng

LuÃ´n tráº£ lá»i ngáº¯n gá»n vÃ  Ä‘i tháº³ng vÃ o váº¥n Ä‘á»."""

def coordinator_agent(state: AgentState):
    messages = state["messages"]
    memory = memory_manager.get_memory()
    conversation_stage = state.get("conversation_stage", "greeting")
    
    print(f"ðŸ” Coordinator Agent - Stage: {conversation_stage}, Messages: {len(messages)}")
    
    # Xá»­ lÃ½ trÆ°á»ng há»£p messages rá»—ng - GREETING
    if not messages:
        response = AIMessage(content="Xin chÃ o! TÃ´i lÃ  trá»£ lÃ½ tÃ³m táº¯t thÃ´ng minh cho há»c sinh tiá»ƒu há»c.\n\nHÃ£y cung cáº¥p vÄƒn báº£n báº¡n muá»‘n tÃ³m táº¯t:")
        memory.add_message("assistant", response.content)
        return {
            "messages": [response],
            "current_agent": "coordinator_agent",
            "needs_user_input": True,
            "conversation_stage": "text_input",
            "original_text": "",
            "summary_type": None,
            "grade_level": 0,
            "processed_text": "",
            "summary_result": "",
            "final_result": ""
        }
    
    last_message = messages[-1]
    
    if isinstance(last_message, HumanMessage):
        user_input = last_message.content
        memory.add_message("user", user_input)
        
        print(f"ðŸ‘¤ User input: {user_input}")
        print(f"ðŸ“Š Conversation stage: {conversation_stage}")
        
        # Xá»­ lÃ½ theo tá»«ng giai Ä‘oáº¡n
        if conversation_stage == "text_input":
            # LÆ°u vÄƒn báº£n gá»‘c vÃ  chuyá»ƒn sang xá»­ lÃ½ OCR/SpellChecker
            response = AIMessage(content="VÄƒn báº£n Ä‘Ã£ Ä‘Æ°á»£c nháº­n! Äang xá»­ lÃ½...")
            memory.add_message("assistant", response.content)
            return {
                "messages": [response],
                "current_agent": "reader_ocr_agent",
                "needs_user_input": False,
                "conversation_stage": "text_input",
                "original_text": user_input,
                "summary_type": None,
                "grade_level": 0,
                "processed_text": "",
                "summary_result": "",
                "final_result": ""
            }
            
        elif conversation_stage == "summary_type":
            # PhÃ¢n tÃ­ch yÃªu cáº§u vá» loáº¡i tÃ³m táº¯t vÃ  khá»‘i lá»›p
            content = user_input.lower()
            if "trÃ­ch xuáº¥t" in content or "extract" in content or "1" in content:
                summary_type = "extract"
            elif "diá»…n giáº£i" in content or "abstract" in content or "2" in content:
                summary_type = "abstract"
            else:
                summary_type = "extract"  # Máº·c Ä‘á»‹nh
            
            # TÃ¬m khá»‘i lá»›p
            grade_level = 3  # Máº·c Ä‘á»‹nh lá»›p 3
            for i in range(1, 6):
                if str(i) in content:
                    grade_level = i
                    break
            
            response = AIMessage(content=f"ÄÃ£ xÃ¡c nháº­n: TÃ³m táº¯t {summary_type} cho lá»›p {grade_level}. Äang xá»­ lÃ½...")
            memory.add_message("assistant", response.content)
            
            return {
                "messages": [response],
                "current_agent": "coordinator_agent",
                "needs_user_input": False,
                "conversation_stage": "processing",
                "original_text": state.get("original_text", ""),
                "summary_type": summary_type,
                "grade_level": grade_level,
                "processed_text": state.get("processed_text", ""),
                "summary_result": "",
                "final_result": ""
            }
            
        elif conversation_stage == "completed":
            # Xá»­ lÃ½ Ä‘Ã¡nh giÃ¡ tá»« user
            if "tá»‘t" in user_input.lower() or "hay" in user_input.lower() or "Ä‘Æ°á»£c" in user_input.lower():
                response = AIMessage(content="Cáº£m Æ¡n báº¡n Ä‘Ã£ Ä‘Ã¡nh giÃ¡ tÃ­ch cá»±c! Há»‡ thá»‘ng sáº½ tiáº¿p tá»¥c cáº£i thiá»‡n.")
            else:
                response = AIMessage(content="Cáº£m Æ¡n báº¡n Ä‘Ã£ Ä‘Ã¡nh giÃ¡! Há»‡ thá»‘ng sáº½ tiáº¿p tá»¥c cáº£i thiá»‡n.")
            
            memory.add_message("assistant", response.content)
            return {
                "messages": [response],
                "current_agent": "coordinator_agent",
                "needs_user_input": True,
                "conversation_stage": "greeting",
                "original_text": "",
                "summary_type": None,
                "grade_level": 0,
                "processed_text": "",
                "summary_result": "",
                "final_result": ""
            }
    
    # Xá»­ lÃ½ khi nháº­n káº¿t quáº£ tá»« Aggregator Agent
    elif conversation_stage == "processing" and state.get("final_result"):
        final_result = state.get("final_result", "")
        response = AIMessage(content=f"ðŸŽ‰ **Káº¾T QUáº¢ TÃ“M Táº®T**\n\n{final_result}\n\n---\n\nBáº¡n cÃ³ hÃ i lÃ²ng vá»›i báº£n tÃ³m táº¯t nÃ y khÃ´ng? HÃ£y Ä‘Ã¡nh giÃ¡ há»‡ thá»‘ng:")
        memory.add_message("assistant", response.content)
        return {
            "messages": [response],
            "current_agent": "coordinator_agent",
            "needs_user_input": True,
            "conversation_stage": "completed",
            "original_text": state.get("original_text", ""),
            "summary_type": state.get("summary_type", None),
            "grade_level": state.get("grade_level", 0),
            "processed_text": state.get("processed_text", ""),
            "summary_result": state.get("summary_result", ""),
            "final_result": final_result
        }
    
    # TrÆ°á»ng há»£p khÃ´ng pháº£i HumanMessage
    return {
        "messages": [],
        "current_agent": "coordinator_agent",
        "needs_user_input": True,
        "conversation_stage": conversation_stage,
        "original_text": state.get("original_text", ""),
        "summary_type": state.get("summary_type", None),
        "grade_level": state.get("grade_level", 0),
        "processed_text": state.get("processed_text", ""),
        "summary_result": state.get("summary_result", ""),
        "final_result": state.get("final_result", "")
    }
    
coordinator_tool = Tool(
    name="CoordinatorAgent",
    func=coordinator_agent,
    description="Use this to get current coordinator for a given task. Input must be a task name."
)